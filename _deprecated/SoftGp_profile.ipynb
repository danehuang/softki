{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import time \n",
    "from tqdm import tqdm \n",
    "import random \n",
    "import torch \n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "import gpytorch\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel\n",
    "from sklearn.cluster import KMeans\n",
    "from linear_operator.settings import max_cholesky_size\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "from gp.util import dynamic_instantiation, flatten_dict, unflatten_dict, flatten_dataset, split_dataset, filter_param, heatmap\n",
    "\n",
    "# System/Library imports\n",
    "from typing import *\n",
    "\n",
    "# Common data science imports\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Gpytorch and linear_operator\n",
    "import gpytorch \n",
    "import gpytorch.constraints\n",
    "from gpytorch.kernels import ScaleKernel\n",
    "import linear_operator\n",
    "from linear_operator.operators.dense_linear_operator import DenseLinearOperator\n",
    "from linear_operator.utils.cholesky import psd_safe_cholesky\n",
    "\n",
    "# Our imports\n",
    "from gp.soft_gp.mll import HutchinsonPseudoLoss\n",
    "from linear_solver.cg import linear_cg\n",
    "\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import torch\n",
    "from os.path import exists\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from seaborn import heatmap\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel\n",
    "from gp.soft_gp.soft_gp import SoftGP\n",
    "\n",
    "from data.get_uci import all_datasets\n",
    "from analysis.util import fetch, init_uci_dict, get_uci_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m filters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbenchmark7\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m }\n\u001b[0;32m----> 4\u001b[0m raw2\u001b[38;5;241m=\u001b[39m \u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msoft-gp-2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Research/soft-gp/analysis/util.py:24\u001b[0m, in \u001b[0;36mfetch\u001b[0;34m(project, filters)\u001b[0m\n\u001b[1;32m     22\u001b[0m hdata \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     23\u001b[0m runs \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mruns(entity \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m project, filters\u001b[38;5;241m=\u001b[39mfilters)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m         hdata\u001b[38;5;241m.\u001b[39mappend(Experiment(run))\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/tqdm/std.py:978\u001b[0m, in \u001b[0;36mtqdm.__init__\u001b[0;34m(self, iterable, desc, total, leave, file, ncols, mininterval, maxinterval, miniters, ascii, disable, unit, unit_scale, dynamic_ncols, smoothing, bar_format, initial, position, postfix, unit_divisor, write_bytes, lock_args, nrows, colour, delay, gui, **kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 978\u001b[0m         total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[1;32m    980\u001b[0m         total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/wandb/apis/paginator.py:32\u001b[0m, in \u001b[0;36mPaginator.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt provide length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/wandb/apis/paginator.py:59\u001b[0m, in \u001b[0;36mPaginator._load_page\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_variables()\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQUERY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjects\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_objects())\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/wandb/sdk/lib/retry.py:212\u001b[0m, in \u001b[0;36mretriable.<locals>.decorator.<locals>.wrapped_fn\u001b[0;34m(*args, **kargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretrier\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/wandb/sdk/lib/retry.py:131\u001b[0m, in \u001b[0;36mRetry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;66;03m# Only print resolved attempts once every minute\u001b[39;00m\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m now \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_print \u001b[38;5;241m>\u001b[39m datetime\u001b[38;5;241m.\u001b[39mtimedelta(\n\u001b[1;32m    134\u001b[0m             minutes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    135\u001b[0m         ):\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/wandb/apis/public/api.py:70\u001b[0m, in \u001b[0;36mRetryingClient.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;129m@retry\u001b[39m\u001b[38;5;241m.\u001b[39mretriable(\n\u001b[1;32m     64\u001b[0m     retry_timedelta\u001b[38;5;241m=\u001b[39mRETRY_TIMEDELTA,\n\u001b[1;32m     65\u001b[0m     check_retry_fn\u001b[38;5;241m=\u001b[39mutil\u001b[38;5;241m.\u001b[39mno_retry_auth,\n\u001b[1;32m     66\u001b[0m     retryable_exceptions\u001b[38;5;241m=\u001b[39m(RetryError, requests\u001b[38;5;241m.\u001b[39mRequestException),\n\u001b[1;32m     67\u001b[0m )\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# noqa: D102  # User not encouraged to use this class directly\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mReadTimeout:\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py:52\u001b[0m, in \u001b[0;36mClient.execute\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate(document)\n\u001b[0;32m---> 52\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39merrors:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(result\u001b[38;5;241m.\u001b[39merrors[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py:60\u001b[0m, in \u001b[0;36mClient._get_result\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, document, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries:\n\u001b[0;32m---> 60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     last_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     retries_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/wandb/sdk/lib/gql_request.py:58\u001b[0m, in \u001b[0;36mGraphQLSession.execute\u001b[0;34m(self, document, variable_values, timeout)\u001b[0m\n\u001b[1;32m     51\u001b[0m data_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_json \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m post_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcookies\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcookies,\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_timeout,\n\u001b[1;32m     56\u001b[0m     data_key: payload,\n\u001b[1;32m     57\u001b[0m }\n\u001b[0;32m---> 58\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpost_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m request\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     61\u001b[0m result \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/requests/sessions.py:637\u001b[0m, in \u001b[0;36mSession.post\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    627\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/http/client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "filters = {\n",
    "    \"group\": \"benchmark7\"\n",
    "}\n",
    "raw2= fetch(\"soft-gp-2\", filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([('pol', 6535, 'soft-gp'), ('pol', 8830, 'soft-gp'), ('pol', 92357, 'soft-gp'), ('elevators', 6535, 'soft-gp'), ('elevators', 8830, 'soft-gp'), ('elevators', 92357, 'soft-gp'), ('bike', 6535, 'soft-gp'), ('bike', 8830, 'soft-gp'), ('bike', 92357, 'soft-gp'), ('kin40k', 6535, 'soft-gp'), ('kin40k', 8830, 'soft-gp'), ('kin40k', 92357, 'soft-gp'), ('protein', 6535, 'soft-gp'), ('protein', 8830, 'soft-gp'), ('protein', 92357, 'soft-gp'), ('keggdirected', 6535, 'soft-gp'), ('keggdirected', 8830, 'soft-gp'), ('keggdirected', 92357, 'soft-gp'), ('slice', 6535, 'soft-gp'), ('slice', 8830, 'soft-gp'), ('slice', 92357, 'soft-gp'), ('keggundirected', 6535, 'soft-gp'), ('keggundirected', 8830, 'soft-gp'), ('keggundirected', 92357, 'soft-gp'), ('3droad', 6535, 'soft-gp'), ('3droad', 8830, 'soft-gp'), ('3droad', 92357, 'soft-gp'), ('song', 6535, 'soft-gp'), ('song', 8830, 'soft-gp'), ('song', 92357, 'soft-gp'), ('buzz', 6535, 'soft-gp'), ('buzz', 8830, 'soft-gp'), ('buzz', 92357, 'soft-gp'), ('houseelectric', 6535, 'soft-gp'), ('houseelectric', 8830, 'soft-gp'), ('houseelectric', 92357, 'soft-gp'), ('pol', 6535, 'exact'), ('elevators', 6535, 'exact')])\n",
      "l 0.7444265484809875 s 0.6444148421287537\n",
      "l 0.771066427230835 s 0.6210245490074158\n",
      "l 0.7983958721160889 s 0.5983002781867981\n",
      "l 0.826429009437561 s 0.5762529969215393\n",
      "l 0.8551770448684692 s 0.5548927783966064\n",
      "l 0.8846474885940552 s 0.5342288017272949\n",
      "l 0.9148438572883606 s 0.5142691135406494\n",
      "l 0.9457650184631348 s 0.4950200915336609\n",
      "l 0.9774048328399658 s 0.4764869213104248\n",
      "l 1.0097516775131226 s 0.4586727023124695\n",
      "l 1.0427885055541992 s 0.44157877564430237\n",
      "l 1.0764926671981812 s 0.4252045750617981\n",
      "l 1.1108355522155762 s 0.4095472991466522\n",
      "l 1.1457836627960205 s 0.3946024477481842\n",
      "l 1.181298017501831 s 0.38036325573921204\n",
      "l 1.2173349857330322 s 0.36682119965553284\n",
      "l 1.2538474798202515 s 0.3539658486843109\n",
      "l 1.2907845973968506 s 0.34178468585014343\n",
      "l 1.3280913829803467 s 0.33026382327079773\n",
      "l 1.3657019138336182 s 0.31939077377319336\n",
      "l 1.4035741090774536 s 0.3091459572315216\n",
      "l 1.4416460990905762 s 0.2995109558105469\n",
      "l 1.4798955917358398 s 0.29046618938446045\n",
      "l 1.5182240009307861 s 0.28199347853660583\n",
      "l 1.5565730333328247 s 0.27407288551330566\n",
      "l 1.594893217086792 s 0.26668813824653625\n",
      "l 1.6330959796905518 s 0.25980687141418457\n",
      "l 1.6711615324020386 s 0.2534162700176239\n",
      "l 1.709043025970459 s 0.24749507009983063\n",
      "l 1.7466990947723389 s 0.24201951920986176\n",
      "l 1.7842121124267578 s 0.23695077002048492\n",
      "l 1.821397066116333 s 0.23229430615901947\n",
      "l 1.8582077026367188 s 0.2280280739068985\n",
      "l 1.8946328163146973 s 0.22413833439350128\n",
      "l 1.9310117959976196 s 0.22064147889614105\n",
      "l 1.9669054746627808 s 0.21747665107250214\n",
      "l 2.0023014545440674 s 0.21462826430797577\n",
      "l 2.0371642112731934 s 0.21207034587860107\n",
      "l 2.0714917182922363 s 0.20979642868041992\n",
      "l 2.105574131011963 s 0.20781636238098145\n",
      "l 2.1389682292938232 s 0.2066235989332199\n",
      "l 2.172370195388794 s 0.2098695933818817\n",
      "l 2.2051196098327637 s 0.2129179984331131\n",
      "l 2.2372193336486816 s 0.21577845513820648\n",
      "l 2.268698215484619 s 0.21846292912960052\n",
      "l 2.299532890319824 s 0.22096991539001465\n",
      "l 2.329753875732422 s 0.22332659363746643\n",
      "l 2.3593788146972656 s 0.2255425751209259\n",
      "l 2.3884682655334473 s 0.22763746976852417\n",
      "l 2.4169366359710693 s 0.22961321473121643\n"
     ]
    }
   ],
   "source": [
    "uci_info = get_uci_info()\n",
    "uci_dict2 = {}\n",
    "for exp in raw2:\n",
    "    model = exp.config[\"model.name\"]\n",
    "    dataset = exp.config[\"dataset.name\"]\n",
    "    dtype = exp.config[\"model.dtype\"]\n",
    "    seed = exp.config[\"training.seed\"]\n",
    "    train_frac = float(exp.config[\"dataset.train_frac\"])\n",
    "    uci_dict2[(dataset, seed, model)] = exp.history\n",
    "\n",
    "print(uci_dict2.keys())\n",
    "def load(dataset):\n",
    "    kernels = []\n",
    "    for epoch_exact in range(1, 51): \n",
    "        kernel = ScaleKernel(RBFKernel())\n",
    "        l = uci_dict2[(dataset, 6535, \"exact\")][\"lengthscale\"][epoch_exact]\n",
    "        s = uci_dict2[(dataset, 6535, \"exact\")][\"outputscale\"][epoch_exact]\n",
    "        kernel.base_kernel.lengthscale = l\n",
    "        kernel.outputscale = s\n",
    "        print(\"l\", l, \"s\", s)\n",
    "        kernels += [kernel]\n",
    "\n",
    "    return kernels\n",
    "\n",
    "\n",
    "kernels = load(\"elevators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (raw_lengthscale_constraint): Positive()\n",
      "  )\n",
      "  (raw_outputscale_constraint): Positive()\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "print(kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft GP testing profiling/tuning boilerplate\n",
    "its recommend to collapse all functions with Ctrl/Cmnd +k +0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SoftGP baseline implementation \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftGP_baseline(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel: Callable,\n",
    "        inducing_points: torch.Tensor,\n",
    "        noise=1e-3,\n",
    "        learn_noise=False,\n",
    "        use_scale=False,\n",
    "        device=\"cpu\",\n",
    "        dtype=torch.float32,\n",
    "        solver=\"solve\",\n",
    "        max_cg_iter=50,\n",
    "        cg_tolerance=0.5,\n",
    "        mll_approx=\"hutchinson\",\n",
    "        fit_chunk_size=1024,\n",
    "        use_qr=False,\n",
    "    ) -> None:\n",
    "        # Argument checking \n",
    "        methods = [\"solve\", \"cholesky\", \"cg\"]\n",
    "        if not solver in methods:\n",
    "            raise ValueError(f\"Method {solver} should be in {methods} ...\")\n",
    "        \n",
    "        # Check devices\n",
    "        devices = [\"cpu\"]\n",
    "        if torch.cuda.is_available():\n",
    "            devices += [\"cuda\"]\n",
    "            for i in range(torch.cuda.device_count()):\n",
    "                devices += [f\"cuda:{i}\"]\n",
    "        if not device in devices:\n",
    "            raise ValueError(f\"Device {device} should be in {devices} ...\")\n",
    "\n",
    "        # Create torch module\n",
    "        super(SoftGP_baseline, self).__init__()\n",
    "\n",
    "        # Misc\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        # Mll approximation settings\n",
    "        self.solve_method = solver\n",
    "        self.mll_approx = mll_approx\n",
    "\n",
    "        # Fit settings\n",
    "        self.use_qr = use_qr\n",
    "        self.fit_chunk_size = fit_chunk_size\n",
    "\n",
    "        # Noise\n",
    "        self.noise_constraint = gpytorch.constraints.Positive()\n",
    "        noise = torch.tensor([noise], dtype=self.dtype, device=self.device)\n",
    "        noise = self.noise_constraint.inverse_transform(noise)\n",
    "        if learn_noise:\n",
    "            self.register_parameter(\"raw_noise\", torch.nn.Parameter(noise))\n",
    "        else:\n",
    "            self.raw_noise = noise\n",
    "\n",
    "        # Kernel\n",
    "        self.use_scale = use_scale\n",
    "        if use_scale:\n",
    "            self.kernel = ScaleKernel(kernel).to(self.device)\n",
    "        else:\n",
    "            self.kernel = kernel.to(self.device)\n",
    "\n",
    "        # Inducing points\n",
    "        self.register_parameter(\"inducing_points\", torch.nn.Parameter(inducing_points))\n",
    "\n",
    "        # Interpolation\n",
    "        def softmax_interp(X: torch.Tensor, sigma_values: torch.Tensor) -> torch.Tensor:\n",
    "            distances = torch.linalg.vector_norm(X - sigma_values, ord=2, dim=-1)\n",
    "            softmax_distances = torch.softmax(-distances, dim=-1)\n",
    "            return softmax_distances\n",
    "        self.interp = softmax_interp\n",
    "        \n",
    "        # Fit artifacts\n",
    "        self.alpha = None\n",
    "        self.K_zz_alpha = None\n",
    "\n",
    "        # CG solver params\n",
    "        self.max_cg_iter = max_cg_iter\n",
    "        self.cg_tol = cg_tolerance\n",
    "        self.x0 = None\n",
    "        \n",
    "    # -----------------------------------------------------\n",
    "    # Soft GP Helpers\n",
    "    # -----------------------------------------------------\n",
    "    \n",
    "    @property\n",
    "    def noise(self):\n",
    "        return self.noise_constraint.transform(self.raw_noise)\n",
    "\n",
    "    def get_lengthscale(self) -> float:\n",
    "        if self.use_scale:\n",
    "            return self.kernel.base_kernel.lengthscale.cpu()\n",
    "        else:\n",
    "            return self.kernel.lengthscale.cpu()\n",
    "        \n",
    "    def get_outputscale(self) -> float:\n",
    "        if self.use_scale:\n",
    "            return self.kernel.outputscale.cpu()\n",
    "        else:\n",
    "            return 1.\n",
    "\n",
    "    def _mk_cov(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return self.kernel(z, z).evaluate()\n",
    "    \n",
    "    def _interp(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_expanded = x.unsqueeze(1).expand(-1, self.inducing_points.shape[0], -1)\n",
    "        W_xz = self.interp(x_expanded, self.inducing_points)\n",
    "        return W_xz\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Linear solver\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    def _solve_system(\n",
    "        self,\n",
    "        kxx: linear_operator.operators.LinearOperator,\n",
    "        full_rhs: torch.Tensor,\n",
    "        x0: torch.Tensor = None,\n",
    "        forwards_matmul: Callable = None,\n",
    "        precond: torch.Tensor = None,\n",
    "        return_pinv: bool = False,\n",
    "    ) -> torch.Tensor:\n",
    "        use_pinv = False\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                if self.solve_method == \"solve\":\n",
    "                    solve = torch.linalg.solve(kxx, full_rhs)\n",
    "                elif self.solve_method == \"cholesky\":\n",
    "                    L = torch.linalg.cholesky(kxx)\n",
    "                    solve = torch.cholesky_solve(full_rhs, L)\n",
    "                elif self.solve_method == \"cg\":\n",
    "                    # Source: https://github.com/AndPotap/halfpres_gps/blob/main/mlls/mixedpresmll.py\n",
    "                    solve = linear_cg(\n",
    "                        forwards_matmul,\n",
    "                        full_rhs,\n",
    "                        max_iter=self.max_cg_iter,\n",
    "                        tolerance=self.cg_tol,\n",
    "                        initial_guess=x0,\n",
    "                        preconditioner=precond,\n",
    "                    )\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown method: {self.solve_method}\")\n",
    "            except RuntimeError as e:\n",
    "                print(\"Fallback to pseudoinverse: \", str(e))\n",
    "                solve = torch.linalg.pinv(kxx.evaluate()) @ full_rhs\n",
    "                use_pinv = True\n",
    "\n",
    "        # Apply torch.nan_to_num to handle NaNs from percision limits \n",
    "        solve = torch.nan_to_num(solve)\n",
    "        return (solve, use_pinv) if return_pinv else solve\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Marginal Log Likelihood\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    def mll(self, X: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute the marginal log likelihood of a soft GP:\n",
    "            \n",
    "            log p(y) = log N(y | mu_x, Q_xx)\n",
    "\n",
    "            where\n",
    "                mu_X: mean of soft GP\n",
    "                Q_XX = W_xz K_zz W_zx\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): B x D tensor of inputs where each row is a point.\n",
    "            y (torch.Tensor): B tensor of targets.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor:  log p(y)\n",
    "        \"\"\"        \n",
    "        # Construct covariance matrix components\n",
    "        K_zz = self._mk_cov(self.inducing_points)\n",
    "        W_xz = self._interp(X)\n",
    "        \n",
    "        if self.mll_approx == \"exact\":\n",
    "            # [Note]: Compute MLL with a multivariate normal. Unstable for float.\n",
    "            # 1. mean: 0\n",
    "            mean = torch.zeros(len(X), dtype=self.dtype, device=self.device)\n",
    "            \n",
    "            # 2. covariance: Q_xx = (W_xz L) (L^T W_xz) + noise I  where K_zz = L L^T\n",
    "            L = psd_safe_cholesky(K_zz)\n",
    "            LK = (W_xz @ L).to(device=self.device)\n",
    "            cov_diag = self.noise * torch.ones(len(X), dtype=self.dtype, device=self.device)\n",
    "\n",
    "            # 3. N(mu, Q_xx)\n",
    "            normal_dist = torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal(mean, LK, cov_diag, validate_args=None)\n",
    "            \n",
    "            # 4. log N(y | mu, Q_xx)\n",
    "            return normal_dist.log_prob(y)\n",
    "        elif self.mll_approx == \"hutchinson\":\n",
    "            # [Note]: Compute MLL with Hutchinson's trace estimator\n",
    "            # 1. mean: 0\n",
    "            mean = torch.zeros(len(X), dtype=self.dtype, device=self.device)\n",
    "            \n",
    "            # 2. covariance: Q_xx = W_xz K_zz K_zx + noise I\n",
    "            cov_mat = W_xz @ K_zz @ W_xz.T \n",
    "            cov_mat += torch.eye(cov_mat.shape[1], dtype=self.dtype, device=self.device) * self.noise\n",
    "\n",
    "            # 3. log N(y | mu, Q_xx) \\appox \n",
    "            hutchinson_mll = HutchinsonPseudoLoss(self, num_trace_samples=10)\n",
    "            return hutchinson_mll(mean, cov_mat, y)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown MLL approximation method: {self.mll_approx}\")\n",
    "        \n",
    "    # -----------------------------------------------------\n",
    "    # Fit\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    def _direct_solve_fit(self, M, N, X, y, K_zz):\n",
    "        # Construct A and b for linear solve\n",
    "        #   A = (K_zz + hat{K}_zx @ noise^{-1} @ hat{K}_xz)\n",
    "        #   b = (hat{K}_zx @ noise^{-1}) y\n",
    "        if X.shape[0] * X.shape[1] <= 32768:\n",
    "            # Case: \"small\" X\n",
    "            # Form estimate \\hat{K}_xz ~= W_xz K_zz\n",
    "            W_xz = self._interp(X)\n",
    "            hat_K_xz = W_xz @ K_zz\n",
    "            hat_K_zx = hat_K_xz.T\n",
    "            \n",
    "            # Form A and b\n",
    "            Lambda_inv_diag = (1 / self.noise) * torch.ones(N, dtype=self.dtype).to(self.device)\n",
    "            A = K_zz + hat_K_zx @ (Lambda_inv_diag.unsqueeze(1) * hat_K_xz)\n",
    "            b = hat_K_zx @ (Lambda_inv_diag * y)\n",
    "        else:\n",
    "            # Case: \"large\" X\n",
    "            with torch.no_grad():\n",
    "                # Initialize outputs\n",
    "                A = torch.zeros(M, M, dtype=self.dtype, device=self.device)\n",
    "                b = torch.zeros(M, dtype=self.dtype, device=self.device)\n",
    "                \n",
    "                # Initialize temporary values\n",
    "                fit_chunk_size = self.fit_chunk_size\n",
    "                batches = int(np.floor(N / fit_chunk_size))\n",
    "                Lambda_inv = (1 / self.noise) * torch.eye(fit_chunk_size, dtype=self.dtype, device=self.device)\n",
    "                tmp1 = torch.zeros(fit_chunk_size, M, dtype=self.dtype, device=self.device)\n",
    "                tmp2 = torch.zeros(M, M, dtype=self.dtype, device=self.device)\n",
    "                tmp3 = torch.zeros(fit_chunk_size, dtype=self.dtype, device=self.device)\n",
    "                tmp4 = torch.zeros(M, dtype=self.dtype, device=self.device)\n",
    "                tmp5 = torch.zeros(M, dtype=self.dtype, device=self.device)\n",
    "                \n",
    "                # Compute batches\n",
    "                for i in range(batches):\n",
    "                    # Update A: A += W_zx @ Lambda_inv @ W_xz\n",
    "                    X_batch = X[i*fit_chunk_size:(i+1)*fit_chunk_size]\n",
    "                    W_xz = self._interp(X_batch)\n",
    "                    W_zx = W_xz.T\n",
    "                    torch.matmul(Lambda_inv, W_xz, out=tmp1)\n",
    "                    torch.matmul(W_zx, tmp1, out=tmp2)\n",
    "                    A.add_(tmp2)\n",
    "                    \n",
    "                    # Update b: b += K_zz @ W_zx @ (Lambda_inv @ Y[i*batch_size:(i+1)*batch_size])\n",
    "                    torch.matmul(Lambda_inv, y[i*fit_chunk_size:(i+1)*fit_chunk_size], out=tmp3)\n",
    "                    torch.matmul(W_zx, tmp3, out=tmp4)\n",
    "                    torch.matmul(K_zz, tmp4, out=tmp5)\n",
    "                    b.add_(tmp5)\n",
    "                \n",
    "                # Compute last batch\n",
    "                if N - (i+1)*fit_chunk_size > 0:\n",
    "                    Lambda_inv = (1 / self.noise) * torch.eye(N - (i+1)*fit_chunk_size, dtype=self.dtype, device=self.device)\n",
    "                    X_batch = X[(i+1)*fit_chunk_size:]\n",
    "                    W_xz = self._interp(X_batch)\n",
    "                    A += W_xz.T @ Lambda_inv @ W_xz\n",
    "                    b += K_zz @ W_xz.T @ Lambda_inv @ y[(i+1)*fit_chunk_size:]\n",
    "\n",
    "                # Aggregate result\n",
    "                A = K_zz + K_zz @ A @ K_zz\n",
    "\n",
    "        # Safe solve A \\alpha = b\n",
    "        A = DenseLinearOperator(A)\n",
    "        self.alpha, use_pinv = self._solve_system(\n",
    "            A,\n",
    "            b.unsqueeze(1),\n",
    "            x0=torch.zeros_like(b),\n",
    "            forwards_matmul=A.matmul,\n",
    "            precond=None,\n",
    "            return_pinv=True\n",
    "        )\n",
    "\n",
    "        # Store for fast prediction\n",
    "        self.K_zz_alpha = K_zz @ self.alpha\n",
    "        return use_pinv\n",
    "\n",
    "    def _qr_solve_fit(self, M, N, X, y, K_zz):\n",
    "        if X.shape[0] * X.shape[1] <= 32768:\n",
    "            # Compute: W_xz K_zz\n",
    "            print(\"USING QR SMALL\")\n",
    "            W_xz = self._interp(X)\n",
    "            hat_K_xz = W_xz @ K_zz\n",
    "        else:\n",
    "            # Compute: W_xz K_zz in a batched fashion\n",
    "            print(\"USING QR BATCH\")\n",
    "            with torch.no_grad():\n",
    "                # Compute batches\n",
    "                fit_chunk_size = self.fit_chunk_size\n",
    "                batches = int(np.floor(N / fit_chunk_size))\n",
    "                Lambda_half_inv_diag = (1 / torch.sqrt(self.noise)) * torch.ones(fit_chunk_size, dtype=self.dtype, device=self.device)\n",
    "                hat_K_xz = torch.zeros((N, M), dtype=self.dtype, device=self.device)\n",
    "                for i in range(batches):\n",
    "                    start = i*fit_chunk_size\n",
    "                    end = (i+1)*fit_chunk_size\n",
    "                    X_batch = X[start:end,:]\n",
    "                    W_xz = self._interp(X_batch)\n",
    "                    torch.matmul(W_xz, K_zz, out=hat_K_xz[start:end,:])\n",
    "                \n",
    "                start = (i+1)*fit_chunk_size\n",
    "                if N - start > 0:\n",
    "                    Lambda_half_inv_diag = (1 / torch.sqrt(self.noise)) * torch.eye(N - (i+1)*fit_chunk_size, dtype=self.dtype, device=self.device)\n",
    "                    X_batch = X[start:]\n",
    "                    W_xz = self._interp(X_batch)\n",
    "                    torch.matmul(W_xz, K_zz, out=hat_K_xz[start:,:])\n",
    "        \n",
    "        # B^T = [(Lambda^{-1/2} \\hat{K}_xz) U_zz ]\n",
    "        U_zz = psd_safe_cholesky(K_zz, upper=True, max_tries=10)\n",
    "        Lambda_half_inv_diag = (1 / torch.sqrt(self.noise)) * torch.ones(N, dtype=self.dtype).to(self.device)\n",
    "        B = torch.cat([Lambda_half_inv_diag.unsqueeze(1) * hat_K_xz, U_zz], dim=0)\n",
    "\n",
    "        # B = QR\n",
    "        Q, R = torch.linalg.qr(B)\n",
    "\n",
    "        # \\alpha = R^{-1} @ Q^T @ Lambda^{-1/2}b\n",
    "        b = Lambda_half_inv_diag * y\n",
    "        self.alpha = torch.linalg.solve_triangular(R, (Q.T[:, 0:N] @ b).unsqueeze(1), upper=True).squeeze(1) # (should use triangular solve)\n",
    "        # self.alpha = ((torch.linalg.inv(R) @ Q.T)[:, :N] @ b)\n",
    "        \n",
    "        # Store for fast inference\n",
    "        self.K_zz_alpha = K_zz @ self.alpha\n",
    "\n",
    "        return False\n",
    "\n",
    "    def fit(self, X: torch.Tensor, y: torch.Tensor) -> bool:\n",
    "        \"\"\"Fits a SoftGP to dataset (X, y). That is, solve:\n",
    "\n",
    "                (hat{K}_zx @ noise^{-1}) y = (K_zz + hat{K}_zx @ noise^{-1} @ hat{K}_xz) \\alpha\n",
    "        \n",
    "            for \\alpha where\n",
    "            1. inducing points z are fixed,\n",
    "            2. hat{K}_zx = K_zz W_zx, and\n",
    "            3. hat{K}_xz = hat{K}_zx^T.\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): N x D tensor of inputs\n",
    "            y (torch.Tensor): N tensor of outputs\n",
    "\n",
    "        Returns:\n",
    "            bool: Returns true if the pseudoinverse was used, false otherwise.\n",
    "        \"\"\"        \n",
    "        # Prepare inputs\n",
    "        N = len(X)\n",
    "        M = len(self.inducing_points)\n",
    "        X = X.to(self.device, dtype=self.dtype)\n",
    "        y = y.to(self.device, dtype=self.dtype)\n",
    "\n",
    "        # Form K_zz\n",
    "        K_zz = self._mk_cov(self.inducing_points)\n",
    "\n",
    "        if self.use_qr:\n",
    "            return self._qr_solve_fit(M, N, X, y, K_zz)\n",
    "        else:\n",
    "            return self._direct_solve_fit(M, N, X, y, K_zz)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Predict\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    def pred(self, x_star: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Give the posterior predictive:\n",
    "        \n",
    "            p(y_star | x_star, X, y) \n",
    "                = W_star_z (K_zz \\alpha)\n",
    "                = W_star_z K_zz (K_zz + hat{K}_zx @ noise^{-1} @ hat{K}_xz)^{-1} (hat{K}_zx @ noise^{-1}) y\n",
    "\n",
    "        Args:\n",
    "            x_star (torch.Tensor): B x D tensor of points to evaluate at.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: B tensor of p(y_star | x_star, X, y).\n",
    "        \"\"\"        \n",
    "        W_star_z = self._interp(x_star)\n",
    "        return torch.matmul(W_star_z, self.K_zz_alpha).squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SoftGP test implementation \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "class SoftGP_test(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel: Callable,\n",
    "        inducing_points: torch.Tensor,\n",
    "        noise=1e-3,\n",
    "        learn_noise=False,\n",
    "        use_scale=False,\n",
    "        device=\"cpu\",\n",
    "        dtype=torch.float32,\n",
    "        solver=\"solve\",\n",
    "        max_cg_iter=50,\n",
    "        cg_tolerance=0.5,\n",
    "        mll_approx=\"hutchinson\",\n",
    "        fit_chunk_size=1024,\n",
    "        use_qr=False,\n",
    "    ) -> None:\n",
    "        # Argument checking \n",
    "        methods = [\"solve\", \"cholesky\", \"cg\"]\n",
    "        if not solver in methods:\n",
    "            raise ValueError(f\"Method {solver} should be in {methods} ...\")\n",
    "        \n",
    "        # Check devices\n",
    "        devices = [\"cpu\"]\n",
    "        if torch.cuda.is_available():\n",
    "            devices += [\"cuda\"]\n",
    "            for i in range(torch.cuda.device_count()):\n",
    "                devices += [f\"cuda:{i}\"]\n",
    "        if not device in devices:\n",
    "            raise ValueError(f\"Device {device} should be in {devices} ...\")\n",
    "\n",
    "        # Create torch module\n",
    "        super(SoftGP_test, self).__init__()\n",
    "\n",
    "        # Misc\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        # Mll approximation settings\n",
    "        self.solve_method = solver\n",
    "        self.mll_approx = mll_approx\n",
    "\n",
    "        # Fit settings\n",
    "        self.use_qr = use_qr\n",
    "        self.fit_chunk_size = fit_chunk_size\n",
    "\n",
    "        # Noise\n",
    "        self.noise_constraint = gpytorch.constraints.Positive()\n",
    "        noise = torch.tensor([noise], dtype=self.dtype, device=self.device)\n",
    "        noise = self.noise_constraint.inverse_transform(noise)\n",
    "        if learn_noise:\n",
    "            self.register_parameter(\"raw_noise\", torch.nn.Parameter(noise))\n",
    "        else:\n",
    "            self.raw_noise = noise\n",
    "\n",
    "        # Kernel\n",
    "        self.use_scale = use_scale\n",
    "        if use_scale:\n",
    "            self.kernel = ScaleKernel(kernel).to(self.device)\n",
    "        else:\n",
    "            self.kernel = kernel.to(self.device)\n",
    "\n",
    "        # Inducing points\n",
    "        self.register_parameter(\"inducing_points\", torch.nn.Parameter(inducing_points))\n",
    "\n",
    "        # Interpolation\n",
    "        #self.threshold = torch.nn.Parameter(torch.tensor(1e-1))\n",
    "        self.k = torch.nn.Parameter(torch.tensor(30.0))\n",
    "        #self.T = torch.nn.Parameter(torch.tensor(1))\n",
    "\n",
    "       \n",
    "            \n",
    "            \n",
    "\n",
    "        # def softmax_interp(X: torch.Tensor, Z: torch.Tensor, T=1, n_neighbors=40,threshold=1e-7) -> torch.Tensor:\n",
    "        #     X=X/T\n",
    "        #     #--------- Distances ---------\n",
    "        #     X_norm = (X**2).sum(dim=1, keepdim=True)  \n",
    "        #     Z_norm = (Z**2).sum(dim=1, keepdim=True) \n",
    "        #     #||X_i - Z_j||^2 = ||X_i||^2 + ||Z_j||^2 - 2*X_i*Z_j\n",
    "        #     distances = X_norm + Z_norm.T - 2 * torch.mm(X, Z.T)\n",
    "            \n",
    "        #     #--------- Thresholding ---------\n",
    "        #     distances = torch.sqrt(torch.clamp(distances, min=threshold)) \n",
    "            \n",
    "        #     #--------- K neighbors ---------\n",
    "        #     _, indices = torch.topk(-distances, k=n_neighbors, dim=1) \n",
    "        #     selected_distances = torch.gather(distances, 1, indices)\n",
    "            \n",
    "        #     #--------- Softmax ---------\n",
    "        #     exp_dists = torch.exp(-selected_distances )\n",
    "        #     W_XZ_local = exp_dists / exp_dists.sum(dim=1, keepdim=True)\n",
    "            \n",
    "        #     # Populate sparse matrix with k values per row\n",
    "        #     W_XZ = torch.zeros((X.size(0), Z.size(0)), device=device)\n",
    "        #     W_XZ.scatter_(1, indices, W_XZ_local)\n",
    "        #     return W_XZ\n",
    "        self.threshold = 1e-32\n",
    "        # self.desired_sparsity=torch.nn.Parameter(torch.tensor(50.0))\n",
    "\n",
    "     \n",
    "        def sparsity_measure(tensor: torch.Tensor) -> float:\n",
    "            \"\"\"Calculate the sparsity of a tensor (ratio of zero elements).\"\"\"\n",
    "            num_zeros = (tensor == 0).sum().item()\n",
    "            total_elements = tensor.numel()\n",
    "            return num_zeros / total_elements\n",
    "\n",
    "        def softmax_interp(X: torch.Tensor, sigma_values: torch.Tensor, threshold_factor: float = 1.0) -> torch.Tensor:\n",
    "            # Compute distances between X and sigma_values\n",
    "            distances = torch.linalg.vector_norm(X - sigma_values, ord=2, dim=-1)\n",
    "            \n",
    "            # Apply softmax to the negative distances\n",
    "            softmax_distances = torch.softmax(-distances, dim=-1)\n",
    "            \n",
    "            # Measure sparsity before applying the threshold\n",
    "            #print(\"Sparsity before masking:\", sparsity_measure(softmax_distances))\n",
    "            \n",
    "            # Set threshold as a factor of the mean of the softmax distances\n",
    "            threshold_value = torch.mean(softmax_distances) * .5\n",
    "            \n",
    "            #print(f\"Threshold value: {threshold_value}\")\n",
    "            \n",
    "            # Apply the threshold: round off (zero out) values below the threshold\n",
    "            masked_distances = torch.where(softmax_distances < threshold_value, torch.tensor(0.0, device=softmax_distances.device), softmax_distances)\n",
    "            \n",
    "            # Measure sparsity after applying the threshold\n",
    "            #print(\"Sparsity after masking:\", sparsity_measure(masked_distances))\n",
    "            \n",
    "            return masked_distances\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        self.interp = softmax_interp\n",
    "\n",
    "        \n",
    "        def sparse_boltz(X: torch.Tensor, sigma_values: torch.Tensor) -> torch.Tensor:\n",
    "            X = X / .005 \n",
    "            \n",
    "            # Calculate distances\n",
    "            distances = torch.linalg.vector_norm(X - sigma_values, ord=2, dim=-1)\n",
    "            \n",
    "            # Apply softmax to distances\n",
    "            softmax_distances = torch.softmax(-distances, dim=-1)\n",
    "            # print(\"Min value:\", softmax_distances.min().item())\n",
    "            # print(\"Max value:\", softmax_distances.max().item())\n",
    "            # print(\"Mean value:\", softmax_distances.mean().item())\n",
    "            # # Apply threshold to create sparsity\n",
    "            threshold = 1e-2\n",
    "            mask = softmax_distances >= threshold\n",
    "            \n",
    "            # Get indices of non-zero (or significant) elements\n",
    "            nonzero_indices = mask.nonzero(as_tuple=False).t()  # Stack the indices as a 2D tensor\n",
    "\n",
    "            # Get values of the non-zero elements\n",
    "            nonzero_values = softmax_distances[mask]\n",
    "\n",
    "            sparse_matrix = torch.sparse_coo_tensor(nonzero_indices, nonzero_values, size=softmax_distances.shape)\n",
    "            \n",
    "            return sparse_matrix\n",
    "        \n",
    "        # def softmax_interp(X: torch.Tensor, sigma_values: torch.Tensor, threshold=1e-3) -> torch.Tensor:\n",
    "        #     X= X/.005\n",
    "        #     distances = torch.linalg.vector_norm(X - sigma_values, ord=2, dim=-1)\n",
    "        #     softmax_distances = torch.softmax(-distances, dim=-1)\n",
    "        #     masked_distances = torch.where(softmax_distances < threshold, torch.tensor(0.0, device=softmax_distances.device), softmax_distances)\n",
    "\n",
    "        #     return masked_distances\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "   \n",
    "        \n",
    "        # Fit artifacts\n",
    "        self.alpha = None\n",
    "        self.K_zz_alpha = None\n",
    "\n",
    "        # CG solver params\n",
    "        self.max_cg_iter = max_cg_iter\n",
    "        self.cg_tol = cg_tolerance\n",
    "        self.x0 = None\n",
    "        \n",
    "    # -----------------------------------------------------\n",
    "    # Soft GP Helpers\n",
    "    # -----------------------------------------------------\n",
    "    \n",
    "    @property\n",
    "    def noise(self):\n",
    "        return self.noise_constraint.transform(self.raw_noise)\n",
    "    \n",
    "  \n",
    "\n",
    "    def seed_threshold(self, X: torch.Tensor, Z: torch.Tensor, desired_sparsity: float = 0.25) -> float:\n",
    "        def sparsity_measure(tensor: torch.Tensor) -> float:\n",
    "        # Count number of zeros in the tensor\n",
    "            num_zeros = (tensor == 0).sum().item()\n",
    "            # Total number of elements\n",
    "            total_elements = tensor.numel()\n",
    "            # Sparsity ratio\n",
    "            return num_zeros / total_elements\n",
    "        \n",
    "        # Randomly select indices from X\n",
    "        random_indices = np.random.randint(0, X.shape[0], 50)\n",
    "        X_samples = torch.tensor(X[random_indices])\n",
    "\n",
    "        # Compute the softmax distances for each selected sample\n",
    "        softmax_distances_list = [self.interp(x.unsqueeze(0), Z) for x in X_samples]\n",
    "        \n",
    "        # Stack the softmax distances into a tensor\n",
    "        softmax_distances_stack = torch.stack(softmax_distances_list)\n",
    "        \n",
    "        # Measure sparsity before applying the threshold\n",
    "        print(\"Sparsity before thresholding:\", sparsity_measure(softmax_distances_stack))\n",
    "        \n",
    "        # Compute the geometric mean of the softmax distances\n",
    "        geometric_mean_softmax = torch.exp(torch.mean(torch.log(softmax_distances_stack), dim=0))\n",
    "        \n",
    "        # Flatten the geometric mean tensor for sorting\n",
    "        geometric_mean_softmax_flattened = geometric_mean_softmax.flatten()\n",
    "        \n",
    "        # Sort the flattened tensor in descending order\n",
    "        sorted_geometric_mean_softmax = torch.sort(geometric_mean_softmax_flattened, descending=True).values\n",
    "        \n",
    "        # Determine the index corresponding to the desired sparsity\n",
    "        threshold_index = int(.5 * len(sorted_geometric_mean_softmax))\n",
    "        \n",
    "        # Get the threshold value\n",
    "        threshold_value = sorted_geometric_mean_softmax[threshold_index].item()\n",
    "        \n",
    "        # Store the threshold value\n",
    "        self.threshold = threshold_value\n",
    "        \n",
    "        # Apply the threshold to the softmax distances to induce sparsity\n",
    "        softmax_distances_stack[softmax_distances_stack < threshold_value] = 0\n",
    "        \n",
    "        # Measure sparsity after applying the threshold\n",
    "        print(\"Sparsity after thresholding:\", sparsity_measure(softmax_distances_stack))\n",
    "\n",
    "            \n",
    "    def get_lengthscale(self) -> float:\n",
    "        if self.use_scale:\n",
    "            return self.kernel.base_kernel.lengthscale.cpu()\n",
    "        else:\n",
    "            return self.kernel.lengthscale.cpu()\n",
    "        \n",
    "    def get_outputscale(self) -> float:\n",
    "        if self.use_scale:\n",
    "            return self.kernel.outputscale.cpu()\n",
    "        else:\n",
    "            return 1.\n",
    "\n",
    "    def _mk_cov(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return self.kernel(z, z).evaluate()\n",
    "    \n",
    "    # def _interp(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    #     # Expand input x and perform interpolation to get the dense matrix W_xz_dense\n",
    "    #     x_expanded = x.unsqueeze(1).expand(-1, self.inducing_points.shape[0], -1)\n",
    "    #     W_xz_dense = self.interp(x_expanded, self.inducing_points)\n",
    "        \n",
    "    #     non_zero_indices = W_xz_dense.nonzero(as_tuple=False).t()  \n",
    "    #     non_zero_values = W_xz_dense[non_zero_indices[0], non_zero_indices[1]]  \n",
    "        \n",
    "    #     W_xz_sparse = torch.sparse_coo_tensor(\n",
    "    #         non_zero_indices, non_zero_values, W_xz_dense.size(), device=W_xz_dense.device\n",
    "    #     )\n",
    "        \n",
    "    #     W_xz_sparse = W_xz_sparse.coalesce()\n",
    "        \n",
    "    #     return W_xz_sparse\n",
    "\n",
    "    def _interp(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_expanded = x.unsqueeze(1).expand(-1, self.inducing_points.shape[0], -1)\n",
    "        W_xz = self.interp(x_expanded, self.inducing_points)\n",
    "        return W_xz\n",
    "    # def _interp(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "    #     W_xz = self.interp(x, self.inducing_points)\n",
    "    #     return W_xz\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Linear solver\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    def _solve_system(\n",
    "        self,\n",
    "        kxx: linear_operator.operators.LinearOperator,\n",
    "        full_rhs: torch.Tensor,\n",
    "        x0: torch.Tensor = None,\n",
    "        forwards_matmul: Callable = None,\n",
    "        precond: torch.Tensor = None,\n",
    "        return_pinv: bool = False,\n",
    "    ) -> torch.Tensor:\n",
    "        use_pinv = False\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                if self.solve_method == \"solve\":\n",
    "                    solve = torch.linalg.solve(kxx, full_rhs)\n",
    "                elif self.solve_method == \"cholesky\":\n",
    "                    L = torch.linalg.cholesky(kxx)\n",
    "                    solve = torch.cholesky_solve(full_rhs, L)\n",
    "                elif self.solve_method == \"cg\":\n",
    "                    # Source: https://github.com/AndPotap/halfpres_gps/blob/main/mlls/mixedpresmll.py\n",
    "                    solve = linear_cg(\n",
    "                        forwards_matmul,\n",
    "                        full_rhs,\n",
    "                        max_iter=self.max_cg_iter,\n",
    "                        tolerance=self.cg_tol,\n",
    "                        initial_guess=x0,\n",
    "                        preconditioner=precond,\n",
    "                    )\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown method: {self.solve_method}\")\n",
    "            except RuntimeError as e:\n",
    "                print(\"Fallback to pseudoinverse: \", str(e))\n",
    "                solve = torch.linalg.pinv(kxx.evaluate()) @ full_rhs\n",
    "                use_pinv = True\n",
    "\n",
    "        # Apply torch.nan_to_num to handle NaNs from percision limits \n",
    "        solve = torch.nan_to_num(solve)\n",
    "        return (solve, use_pinv) if return_pinv else solve\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Marginal Log Likelihood\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    def mll(self, X: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute the marginal log likelihood of a soft GP:\n",
    "            \n",
    "            log p(y) = log N(y | mu_x, Q_xx)\n",
    "\n",
    "            where\n",
    "                mu_X: mean of soft GP\n",
    "                Q_XX = W_xz K_zz W_zx\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): B x D tensor of inputs where each row is a point.\n",
    "            y (torch.Tensor): B tensor of targets.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor:  log p(y)\n",
    "        \"\"\"        \n",
    "        # Construct covariance matrix components\n",
    "        K_zz = self._mk_cov(self.inducing_points)\n",
    "        W_xz = self._interp(X)\n",
    "        \n",
    "        if self.mll_approx == \"exact\":\n",
    "            # [Note]: Compute MLL with a multivariate normal. Unstable for float.\n",
    "            # 1. mean: 0\n",
    "            mean = torch.zeros(len(X), dtype=self.dtype, device=self.device)\n",
    "            \n",
    "            # 2. covariance: Q_xx = (W_xz L) (L^T W_xz) + noise I  where K_zz = L L^T\n",
    "            L = psd_safe_cholesky(K_zz)\n",
    "            LK = (W_xz @ L).to(device=self.device)\n",
    "            cov_diag = self.noise * torch.ones(len(X), dtype=self.dtype, device=self.device)\n",
    "\n",
    "            # 3. N(mu, Q_xx)\n",
    "            normal_dist = torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal(mean, LK, cov_diag, validate_args=None)\n",
    "            \n",
    "            # 4. log N(y | mu, Q_xx)\n",
    "            return normal_dist.log_prob(y)\n",
    "        \n",
    "        elif self.mll_approx == \"hutchinson\":\n",
    "            # [Note]: Compute MLL with Hutchinson's trace estimator\n",
    "            # 1. mean: 0\n",
    "            mean = torch.zeros(len(X), dtype=self.dtype, device=self.device)\n",
    "            \n",
    "            # 2. covariance: Q_xx = W_xz K_zz K_zx + noise I\n",
    "            # cov_mat = W_xz @ K_zz @ W_xz.T \n",
    "            cov_mat = W_xz @ K_zz @ W_xz.T \n",
    "            # cov_mat = torch.sparse.mm(W_xz, K_zz)  # First sparse-dense multiplication (W_xz @ K_zz)\n",
    "            # cov_mat = torch.sparse.mm(cov_mat, W_xz.t())  # Second multiplication with W_xz^T (transpose)\n",
    "            cov_mat += torch.eye(cov_mat.shape[1], dtype=self.dtype, device=self.device) * self.noise\n",
    "\n",
    "            # 3. log N(y | mu, Q_xx) \\appox \n",
    "            hutchinson_mll = HutchinsonPseudoLoss(self, num_trace_samples=10,vector_format=\"sphere\")\n",
    "            return hutchinson_mll(mean, cov_mat, y)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown MLL approximation method: {self.mll_approx}\")\n",
    "        \n",
    "    # -----------------------------------------------------\n",
    "    # Fit\n",
    "    # -----------------------------------------------------\n",
    "    def _direct_solve_fit(self, M, N, X, y, K_zz):\n",
    "        # Construct A and b for linear solve\n",
    "        #   A = (K_zz + hat{K}_zx @ noise^{-1} @ hat{K}_xz)\n",
    "        #   b = (hat{K}_zx @ noise^{-1}) y\n",
    "        if X.shape[0] * X.shape[1] <= 32768:\n",
    "            # Case: \"small\" X\n",
    "            # Form estimate \\hat{K}_xz ~= W_xz K_zz\n",
    "            W_xz = self._interp(X)\n",
    "            hat_K_xz = W_xz @ K_zz\n",
    "            \n",
    "            hat_K_zx = hat_K_xz.T\n",
    "\n",
    "            # Form A and b\n",
    "            Lambda_inv_diag = (1 / self.noise) * torch.ones(N, dtype=self.dtype).to(self.device)\n",
    "            A = K_zz + hat_K_zx @ (Lambda_inv_diag.unsqueeze(1) * hat_K_xz)\n",
    "            b = hat_K_zx @ (Lambda_inv_diag * y)\n",
    "        else:\n",
    "            # Case: \"large\" X\n",
    "            with torch.no_grad():\n",
    "                # Initialize outputs\n",
    "                A = torch.zeros(M, M, dtype=self.dtype, device=self.device)\n",
    "                b = torch.zeros(M, dtype=self.dtype, device=self.device)\n",
    "                \n",
    "                # Initialize temporary values\n",
    "                fit_chunk_size = self.fit_chunk_size\n",
    "                batches = int(np.floor(N / fit_chunk_size))\n",
    "                Lambda_inv = (1 / self.noise) * torch.eye(fit_chunk_size, dtype=self.dtype, device=self.device)\n",
    "                tmp1 = torch.zeros(fit_chunk_size, M, dtype=self.dtype, device=self.device)\n",
    "                tmp2 = torch.zeros(M, M, dtype=self.dtype, device=self.device)\n",
    "                tmp3 = torch.zeros(fit_chunk_size, dtype=self.dtype, device=self.device)\n",
    "                tmp4 = torch.zeros(M, dtype=self.dtype, device=self.device)\n",
    "                tmp5 = torch.zeros(M, dtype=self.dtype, device=self.device)\n",
    "                \n",
    "                # Compute batches\n",
    "                for i in range(batches):\n",
    "                    # Update A: A += W_zx @ Lambda_inv @ W_xz\n",
    "                    X_batch = X[i*fit_chunk_size:(i+1)*fit_chunk_size]\n",
    "                    W_xz = self._interp(X_batch)\n",
    "                    W_zx = W_xz.T\n",
    "                    torch.matmul(Lambda_inv, W_xz, out=tmp1)\n",
    "                    torch.matmul(W_zx, tmp1, out=tmp2)\n",
    "                    A.add_(tmp2)\n",
    "                    \n",
    "                    # Update b: b += K_zz @ W_zx @ (Lambda_inv @ Y[i*batch_size:(i+1)*batch_size])\n",
    "                    torch.matmul(Lambda_inv, y[i*fit_chunk_size:(i+1)*fit_chunk_size], out=tmp3)\n",
    "                    torch.matmul(W_zx, tmp3, out=tmp4)\n",
    "                    torch.matmul(K_zz, tmp4, out=tmp5)\n",
    "                    b.add_(tmp5)\n",
    "                \n",
    "                # Compute last batch\n",
    "                if N - (i+1)*fit_chunk_size > 0:\n",
    "                    Lambda_inv = (1 / self.noise) * torch.eye(N - (i+1)*fit_chunk_size, dtype=self.dtype, device=self.device)\n",
    "                    X_batch = X[(i+1)*fit_chunk_size:]\n",
    "                    W_xz = self._interp(X_batch)\n",
    "                    A += W_xz.T @ Lambda_inv @ W_xz\n",
    "                    b += K_zz @ W_xz.T @ Lambda_inv @ y[(i+1)*fit_chunk_size:]\n",
    "\n",
    "                # Aggregate result\n",
    "                A = K_zz + K_zz @ A @ K_zz\n",
    "\n",
    "        # Safe solve A \\alpha = b\n",
    "        A = DenseLinearOperator(A)\n",
    "        self.alpha, use_pinv = self._solve_system(\n",
    "            A,\n",
    "            b.unsqueeze(1),\n",
    "            x0=torch.zeros_like(b),\n",
    "            forwards_matmul=A.matmul,\n",
    "            precond=None,\n",
    "            return_pinv=True\n",
    "        )\n",
    "\n",
    "        # Store for fast prediction\n",
    "        self.K_zz_alpha = K_zz @ self.alpha\n",
    "        return use_pinv\n",
    " \n",
    "    def _qr_solve_fit(self, M, N, X, y, K_zz):\n",
    "        # W_xz = self._interp(X)\n",
    "        # hat_K_xz = W_xz @ K_zz\n",
    "        if X.shape[0] * X.shape[1] <= 32768:\n",
    "            # Compute: W_xz K_zz\n",
    "            print(\"USING QR SMALL\")\n",
    "            W_xz = self._interp(X)\n",
    "            hat_K_xz = W_xz @ K_zz\n",
    "        else:\n",
    "            # Compute: W_xz K_zz in a batched fashion\n",
    "            print(\"USING QR BATCH\")\n",
    "            with torch.no_grad():\n",
    "                # Compute batches\n",
    "                fit_chunk_size = self.fit_chunk_size\n",
    "                batches = int(np.floor(N / fit_chunk_size))\n",
    "                Lambda_half_inv_diag = (1 / torch.sqrt(self.noise)) * torch.ones(fit_chunk_size, dtype=self.dtype, device=self.device)\n",
    "                hat_K_xz = torch.zeros((N, M), dtype=self.dtype, device=self.device)\n",
    "                for i in range(batches):\n",
    "                    start = i*fit_chunk_size\n",
    "                    end = (i+1)*fit_chunk_size\n",
    "                    X_batch = X[start:end,:]\n",
    "                    W_xz = self._interp(X_batch)\n",
    "                    \n",
    "                    # sparsity = 1.0 - W_xz._nnz() / float(W_xz.numel())\n",
    "                    # print(f\"Sparsity: {sparsity}\")\n",
    "               \n",
    "                    #result = torch.sparse.mm(W_xz, K_zz)\n",
    "                    #hat_K_xz[start:end, :] = result\n",
    "                    torch.matmul(W_xz, K_zz, out=hat_K_xz[start:end,:])\n",
    "                                \n",
    "                start = (i+1)*fit_chunk_size\n",
    "                if N - start > 0:\n",
    "                    Lambda_half_inv_diag = (1 / torch.sqrt(self.noise)) * torch.eye(N - (i+1)*fit_chunk_size, dtype=self.dtype, device=self.device)\n",
    "                    X_batch = X[start:]\n",
    "                    W_xz = self._interp(X_batch)\n",
    "                    #result = torch.sparse.mm(W_xz, K_zz)\n",
    "                    #hat_K_xz[start:, :] = result\n",
    "                    torch.matmul(W_xz, K_zz, out=hat_K_xz[start:,:])\n",
    "                    \n",
    "\n",
    "        \n",
    "        # B^T = [(Lambda^{-1/2} \\hat{K}_xz) U_zz ]\n",
    "        U_zz = psd_safe_cholesky(K_zz, upper=True, max_tries=10)\n",
    "        Lambda_half_inv_diag = (1 / torch.sqrt(self.noise)) * torch.ones(N, dtype=self.dtype).to(self.device)\n",
    "        B = torch.cat([Lambda_half_inv_diag.unsqueeze(1) * hat_K_xz, U_zz], dim=0)\n",
    "\n",
    "        # B = QR\n",
    "        Q, R = torch.linalg.qr(B)\n",
    "\n",
    "        # \\alpha = R^{-1} @ Q^T @ Lambda^{-1/2}b\n",
    "        b = Lambda_half_inv_diag * y\n",
    "        self.alpha = torch.linalg.solve_triangular(R, (Q.T[:, 0:N] @ b).unsqueeze(1), upper=True).squeeze(1) # (should use triangular solve)\n",
    "        # Store for fast inference\n",
    "        self.K_zz_alpha = (K_zz) @ self.alpha \n",
    "\n",
    "        #self.K_zz_alpha = (K_zz+ self.noise * torch.eye(K_zz.shape[0],dtype=self.dtype).to(self.device)) @ self.alpha \n",
    "\n",
    "        return False\n",
    "\n",
    "    def fit(self, X: torch.Tensor, y: torch.Tensor) -> bool:\n",
    "        \"\"\"Fits a SoftGP to dataset (X, y). That is, solve:\n",
    "\n",
    "                (hat{K}_zx @ noise^{-1}) y = (K_zz + hat{K}_zx @ noise^{-1} @ hat{K}_xz) \\alpha\n",
    "        \n",
    "            for \\alpha where\n",
    "            1. inducing points z are fixed,\n",
    "            2. hat{K}_zx = K_zz W_zx, and\n",
    "            3. hat{K}_xz = hat{K}_zx^T.\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): N x D tensor of inputs\n",
    "            y (torch.Tensor): N tensor of outputs\n",
    "\n",
    "        Returns:\n",
    "            bool: Returns true if the pseudoinverse was used, false otherwise.\n",
    "        \"\"\"        \n",
    "        # Prepare inputs\n",
    "        N = len(X)\n",
    "        M = len(self.inducing_points)\n",
    "        X = X.to(self.device, dtype=self.dtype)\n",
    "        y = y.to(self.device, dtype=self.dtype)\n",
    "\n",
    "        # Form K_zz\n",
    "        K_zz = self._mk_cov(self.inducing_points)\n",
    "\n",
    "        if self.use_qr:\n",
    "            return self._qr_solve_fit(M, N, X, y, K_zz)\n",
    "        else:\n",
    "            return self._direct_solve_fit(M, N, X, y, K_zz)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Predict\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    def pred(self, x_star: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Give the posterior predictive:\n",
    "        \n",
    "            p(y_star | x_star, X, y) \n",
    "                = W_star_z (K_zz \\alpha)\n",
    "                = W_star_z K_zz (K_zz + hat{K}_zx @ noise^{-1} @ hat{K}_xz)^{-1} (hat{K}_zx @ noise^{-1}) y\n",
    "\n",
    "        Args:\n",
    "            x_star (torch.Tensor): B x D tensor of points to evaluate at.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: B tensor of p(y_star | x_star, X, y).\n",
    "        \"\"\"        \n",
    "        W_star_z = self._interp(x_star)\n",
    "        return torch.matmul(W_star_z, self.K_zz_alpha).squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test version profiling stats\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from line_profiler import LineProfiler\n",
    "\n",
    "def eval_gp(model, test_dataset: Dataset, device=\"cuda:0\") -> float:\n",
    "    preds = []\n",
    "    neg_mlls = []\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,num_workers=1)\n",
    "    for x_batch, y_batch in tqdm(test_loader):\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        preds += [(model.pred(x_batch) - y_batch).detach().cpu()**2]\n",
    "        neg_mlls += [-model.mll(x_batch, y_batch).detach().cpu()]\n",
    "    rmse = torch.sqrt(torch.sum(torch.cat(preds)) / len(test_dataset)).item()\n",
    "    neg_mll = torch.sum(torch.tensor(neg_mlls))\n",
    "            \n",
    "    print(\"RMSE:\", rmse, \"NEG_MLL\", neg_mll.item(), \"NOISE\", model.noise.cpu().item(), \"LENGTHSCALE\", model.get_lengthscale(), \"OUTPUTSCALE\", model.get_outputscale(),\"k\",model.k)# \"T\",model.T)\n",
    "    \n",
    "    return {\n",
    "        \"rmse\": rmse,\n",
    "        \"nll\": neg_mll,\n",
    "    }   \n",
    "    \n",
    "def profileGP(GP,train_dataset, test_dataset):\n",
    "    num_inducing = 512\n",
    "    dtype = torch.float32\n",
    "    batch_size = 1024\n",
    "    epochs = 3\n",
    "    lr = 0.01 \n",
    "    learn_noise = False\n",
    "    device = \"cpu\"\n",
    "    \n",
    "    # Initialize inducing points with kmeans\n",
    "    train_features, train_labels = flatten_dataset(train_dataset)\n",
    "    kmeans = KMeans(n_clusters=num_inducing)\n",
    "    kmeans.fit(train_features)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    inducing_points = torch.tensor(centers).to(dtype=dtype, device=device)\n",
    "    \n",
    "    # Setup model\n",
    "    kernel = RBFKernel().to(device=device, dtype=dtype)\n",
    "\n",
    "    model = GP(kernel,\n",
    "        inducing_points,\n",
    "        noise=1e-3,\n",
    "        learn_noise=learn_noise,\n",
    "        use_scale=True,\n",
    "        dtype=dtype,\n",
    "        solver=\"solve\",\n",
    "        max_cg_iter=50,\n",
    "        cg_tolerance=0.5,\n",
    "        mll_approx=\"hutchinson\",\n",
    "        fit_chunk_size=1024,\n",
    "        use_qr=True,\n",
    "    )\n",
    "\n",
    "    if learn_noise:\n",
    "        params = model.parameters()\n",
    "    else:\n",
    "        params = filter_param(model.named_parameters(), \"likelihood.noise_covar.raw_noise\")\n",
    "    optimizer = torch.optim.Adam(params, lr=lr)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    pbar = tqdm(range(epochs), desc=\"Optimizing MLL\")\n",
    "    def train_model():\n",
    "        print(\"test\")\n",
    "        for epoch in pbar:\n",
    "            t1 = time.perf_counter()\n",
    "            \n",
    "            neg_mlls = []\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch = x_batch.clone().detach().to(dtype=dtype, device=device)\n",
    "                y_batch = y_batch.clone().detach().to(dtype=dtype, device=device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                with gpytorch.settings.max_root_decomposition_size(100), max_cholesky_size(int(1.e7)):\n",
    "                    neg_mll = -model.mll(x_batch, y_batch)\n",
    "                neg_mlls += [-neg_mll.item()]\n",
    "                neg_mll.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                pbar.set_description(f\"Epoch {epoch+1}/{epochs}\")\n",
    "                pbar.set_postfix(MLL=f\"{-neg_mll.item()}\")\n",
    "                \n",
    "            t2 = time.perf_counter()\n",
    "            #print(\"fitting\",train_features.shape)\n",
    "            use_pinv = model.fit(train_features, train_labels)\n",
    "            t3 = time.perf_counter()\n",
    "            # Calculate time spent on each part\n",
    "            epoch_time = t2 - t1\n",
    "            fitting_time = t3 - t2\n",
    "            \n",
    "            # Print out the times for the epoch and model fitting\n",
    "            print(f\"Epoch {epoch+1}/{epochs} completed in {epoch_time:.4f} seconds.\")\n",
    "            print(f\"Time spent on model fitting: {fitting_time:.4f} seconds.\")\n",
    "        \n",
    "            #results = eval_gp(model, test_dataset, device=device)\n",
    "            #print(results)\n",
    "    profiler = LineProfiler()\n",
    "    profiler.add_function(train_model)\n",
    "    profiler.add_function(model.fit)  \n",
    "    profiler.add_function(model.interp)  \n",
    "    profiler.add_function(model._qr_solve_fit) \n",
    "    profiler.add_function(model.mll)  \n",
    "\n",
    "\n",
    "    profiler.enable_by_count()\n",
    "    train_model() \n",
    "    profiler.disable_by_count()\n",
    "    profiler.print_stats()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Total time  22.1084 s  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE (53500, 386)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0bb9b42a536465980dd00a4bb6d582d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 17\u001b[0m\n\u001b[1;32m     10\u001b[0m dataset \u001b[38;5;241m=\u001b[39m CTSlicesDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/uci_datasets/uci_datasets/slice/data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m train_dataset, val_dataset, test_dataset \u001b[38;5;241m=\u001b[39m split_dataset(\n\u001b[1;32m     12\u001b[0m     dataset,\n\u001b[1;32m     13\u001b[0m     train_frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     14\u001b[0m     val_frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m softgp \u001b[38;5;241m=\u001b[39m \u001b[43mprofileGP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSoftGP_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[54], line 34\u001b[0m, in \u001b[0;36mprofileGP\u001b[0;34m(GP, train_dataset, test_dataset)\u001b[0m\n\u001b[1;32m     32\u001b[0m train_features, train_labels \u001b[38;5;241m=\u001b[39m flatten_dataset(train_dataset)\n\u001b[1;32m     33\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mnum_inducing)\n\u001b[0;32m---> 34\u001b[0m \u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m centers \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mcluster_centers_\n\u001b[1;32m     36\u001b[0m inducing_points \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(centers)\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1464\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[1;32m   1439\u001b[0m \n\u001b[1;32m   1440\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1464\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m   1475\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/sklearn/utils/validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/sklearn/utils/validation.py:119\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# error message.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 119\u001b[0m     first_pass_isfinite \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39misfinite(\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/numpy/core/fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2314\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from data.get_uci import ElevatorsDataset,PoleteleDataset,CTSlicesDataset\n",
    "# dataset = PoleteleDataset(\"../data/uci_datasets/uci_datasets/pol/data.csv\")\n",
    "# train_dataset, val_dataset, test_dataset = split_dataset(\n",
    "#     dataset,\n",
    "#     train_frac=9/10,\n",
    "#     val_frac=0/10\n",
    "# )\n",
    "\n",
    "\n",
    "dataset = CTSlicesDataset(\"../data/uci_datasets/uci_datasets/slice/data.csv\")\n",
    "train_dataset, val_dataset, test_dataset = split_dataset(\n",
    "    dataset,\n",
    "    train_frac=9/10,\n",
    "    val_frac=0/10\n",
    ")\n",
    "\n",
    "softgp = profileGP(SoftGP_test,train_dataset,test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison: Test vs Baseline \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE (15000, 27)\n"
     ]
    }
   ],
   "source": [
    "#==================Dataset============================\n",
    "from data.get_uci import ElevatorsDataset,PoleteleDataset\n",
    "# # dataset = ElevatorsDataset(\"../data/uci_datasets/uci_datasets/elevators/data.csv\")\n",
    "dataset = PoleteleDataset(\"../data/uci_datasets/uci_datasets/pol/data.csv\")\n",
    "\n",
    "# train_dataset, val_dataset, test_dataset = split_dataset(\n",
    "#     dataset,\n",
    "#     train_frac=9/10,\n",
    "#     val_frac=0/10  \n",
    "# )\n",
    "\n",
    "\n",
    "# dataset = CTSlicesDataset(\"../data/uci_datasets/uci_datasets/slice/data.csv\")\n",
    "train_dataset, val_dataset, test_dataset = split_dataset(\n",
    "    dataset,\n",
    "    train_frac=9/10,\n",
    "    val_frac=0/10\n",
    ")\n",
    "\n",
    "def plot_results(GP_classes, all_mean_rmse, all_mean_runtimes, all_std_rmse, all_std_runtimes, epochs):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    for i, GP_class in enumerate(GP_classes):\n",
    "        epochs_range = range(1, epochs + 1)\n",
    "        axes[0].plot(epochs_range, all_mean_rmse[i], label=f'{GP_class.__name__} RMSE')\n",
    "        axes[0].fill_between(epochs_range,\n",
    "                             [m - s for m, s in zip(all_mean_rmse[i], all_std_rmse[i])],\n",
    "                             [m + s for m, s in zip(all_mean_rmse[i], all_std_rmse[i])],\n",
    "                             alpha=0.3)\n",
    "    axes[0].set_title('RMSE per Epoch')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('RMSE')\n",
    "    axes[0].legend()\n",
    "\n",
    "    for i, GP_class in enumerate(GP_classes):\n",
    "        epochs_range = range(1, epochs + 1)\n",
    "        axes[1].plot(epochs_range, all_mean_runtimes[i], label=f'{GP_class.__name__} Runtime')\n",
    "        axes[1].fill_between(epochs_range,\n",
    "                             [m - s for m, s in zip(all_mean_runtimes[i], all_std_runtimes[i])],\n",
    "                             [m + s for m, s in zip(all_mean_runtimes[i], all_std_runtimes[i])],\n",
    "                             alpha=0.3)\n",
    "    axes[1].set_title('Training Time per Epoch')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Time (s)')\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def train_gp(GP_class, inducing_points, test_dataset, train_features, train_labels, epochs, device, dtype):\n",
    "    kernel = RBFKernel().to(device=device, dtype=dtype)\n",
    "    learn_noise = False\n",
    "    lr = .01\n",
    "    batch_size = 1024\n",
    "\n",
    "    model = GP_class(kernel,\n",
    "                     inducing_points,\n",
    "                     noise=1e-3,\n",
    "                     learn_noise=learn_noise,\n",
    "                     \n",
    "                     use_scale=True,\n",
    "                     dtype=dtype,\n",
    "                     solver=\"solve\",\n",
    "                     max_cg_iter=50,\n",
    "                     cg_tolerance=0.5,\n",
    "                     mll_approx=\"hutchinson\",\n",
    "                     fit_chunk_size=1024,\n",
    "                     use_qr=True)\n",
    "\n",
    "    epoch_runtimes = []\n",
    "    epoch_rmse = []\n",
    "\n",
    "    # pbar = tqdm(range(epochs), desc=\"Optimizing MLL\")\n",
    "    if learn_noise:\n",
    "        params = model.parameters()\n",
    "    else:\n",
    "        params = filter_param(model.named_parameters(), \"likelihood.noise_covar.raw_noise\")\n",
    "    optimizer = torch.optim.Adam(params, lr=lr)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # if GP_class  ==SoftGP_test:\n",
    "    #     model.seed_threshold(train_features,inducing_points,desired_sparsity=.5)\n",
    "        \n",
    "    def train_model():\n",
    "        #==================Train============================\n",
    "        for _ in tqdm(range(epochs)):\n",
    "            print(\"training current epoch\")\n",
    "            epoch_start_time = time.time()\n",
    "\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch = x_batch.clone().detach().to(dtype=dtype, device=device)\n",
    "                y_batch = y_batch.clone().detach().to(dtype=dtype, device=device)\n",
    "                optimizer.zero_grad()\n",
    "                with gpytorch.settings.max_root_decomposition_size(100), max_cholesky_size(int(1.e7)):\n",
    "                    neg_mll = -model.mll(x_batch, y_batch)\n",
    "                neg_mll.backward()\n",
    "                optimizer.step()\n",
    "                # pbar.set_description(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "                # pbar.set_postfix(MLL=f\"{-neg_mll.item()}\")\n",
    "            model.fit(train_features, train_labels)\n",
    "            epoch_end_time = time.time()\n",
    "            epoch_runtimes.append(epoch_end_time - epoch_start_time)\n",
    "\n",
    "            #==================Evaluate============================\n",
    "            print(\"Running eval\")\n",
    "            eval_results = eval_gp(model, test_dataset, device=device)\n",
    "            epoch_rmse.append(eval_results['rmse'])\n",
    "            print(\"eval finished\")    \n",
    "    train_model()\n",
    "    return epoch_rmse, epoch_runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94e6d0cecbd40c68d720538083b78c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SoftGP_test...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b559e3156642cfb7db0cf8ed34ccd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600458bc75054836b33df0571bd721de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2595203220844269 NEG_MLL -1394.49462890625 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6315]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(0.7653, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495038d3754345b38be11624f193d68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.24740484356880188 NEG_MLL -1371.0137939453125 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6065]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(0.8373, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbaffe8c6e44f53a8094b5017d0d06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.24221740663051605 NEG_MLL -1303.1715087890625 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6111]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(0.9106, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c01a1cc92047b395e4f32f04d0e329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.23815147578716278 NEG_MLL -1223.810302734375 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6287]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(0.9854, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ccdb7290cf14d30ae7ff617bad6d18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2349194884300232 NEG_MLL -1149.45068359375 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6491]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(1.0600, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52548206e22d48248be0a7329062e6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2322375625371933 NEG_MLL -1100.5086669921875 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6622]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(1.1348, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edadefbd950a4b768bf7263d5304709f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2309694141149521 NEG_MLL -1051.3189697265625 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6691]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(1.2104, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfe26ebf22242d1b1524558e3f71643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.22920764982700348 NEG_MLL -1010.8848266601562 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6721]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(1.2854, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5e8752a98e423fbceed93e0917ecdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.22774824500083923 NEG_MLL -971.176513671875 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6698]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(1.3630, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c957591b9939431d9a3c69fb27673388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2259245216846466 NEG_MLL -933.2472534179688 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6671]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(1.4396, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef7e87be20b404aa056292ef0b069f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.22519129514694214 NEG_MLL -904.427734375 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6631]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(1.5162, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2203388504643fba3cb12875b5a8674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.22364568710327148 NEG_MLL -876.8345336914062 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6587]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(1.5919, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87899223270f4e3e82e597aafd765a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.22229516506195068 NEG_MLL -846.5908813476562 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6494]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(1.6687, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5759c41a5ac4a069ed42a7d15d7e444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2211017906665802 NEG_MLL -826.352783203125 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6392]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(1.7437, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ba2db3df2d439b94f01c81d2f6b389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2193845510482788 NEG_MLL -805.601318359375 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6288]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(1.8181, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f39abcf7a94d39bc1362ec90260ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.21775978803634644 NEG_MLL -787.3208618164062 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6189]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(1.8929, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb647dbd8a84ec39d4adbb2452b6e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.21718920767307281 NEG_MLL -767.9110107421875 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6073]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(1.9684, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46859488c8524688be9332f6c8ca681c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.21493051946163177 NEG_MLL -753.1427001953125 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.5941]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(2.0432, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b6220c9de24abc839f7d31916133d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.21463388204574585 NEG_MLL -734.5127563476562 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.5813]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(2.1185, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ead8ea21a034f61a6c7905561447ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.21445152163505554 NEG_MLL -720.14501953125 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.5716]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(2.1927, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98111627e2242f5a0ac9a96439d3fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2135833501815796 NEG_MLL -705.0137939453125 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.5652]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(2.2660, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a658aa47a6d44771bcc5a9bef877ee63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2119896113872528 NEG_MLL -689.9107055664062 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.5580]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(2.3378, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782aab525d91487480b2669a34343cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.21106858551502228 NEG_MLL -678.4403686523438 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.5478]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(2.4088, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c7a62f459bc4f96b567538f3e4cf847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.21021433174610138 NEG_MLL -668.0677490234375 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.5385]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(2.4798, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46856063ee7547e5bf8e070ca5d223ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.20983679592609406 NEG_MLL -655.2451171875 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.5295]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(2.5515, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7348ee9c882d4098ba2806ab9568b0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2091773897409439 NEG_MLL -641.8870849609375 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.5176]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(2.6225, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4c4dfb8e934d25a70a020982ee7b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.20894791185855865 NEG_MLL -635.5533447265625 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.5069]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(2.6916, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814028edab514c0d8a36cda7ecc6a938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.20779964327812195 NEG_MLL -627.4630737304688 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.4986]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(2.7600, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8522dbea9b14d77a69d921f8b71c17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2075592428445816 NEG_MLL -613.1063842773438 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.4921]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(2.8292, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1cc6ca015da4efd93310414c4059ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.20726996660232544 NEG_MLL -605.0144653320312 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.4848]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(2.8979, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e2ccd108ab4c19b1acf3ab95d681c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2073953002691269 NEG_MLL -595.076416015625 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.4763]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(2.9651, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf509b508b9c416891f9ec8fa331d044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.20629826188087463 NEG_MLL -584.47900390625 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.4685]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(3.0307, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c33ea2cef6d4a66b8055124056f9d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.20574474334716797 NEG_MLL -577.5623168945312 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.4604]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(3.0953, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506810570888400380ef598b113d2cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.20458050072193146 NEG_MLL -569.2518310546875 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.4516]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(3.1613, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4dbce6aa2584f0d9cb702eb84bfb9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.20519064366817474 NEG_MLL -563.0997924804688 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.4446]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(3.2254, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb10270424a4e4b93f728a2d2891713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.20553742349147797 NEG_MLL -555.9343872070312 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.4391]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(3.2874, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3678add28f49a9b495b5156f71ad10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.20518353581428528 NEG_MLL -545.2118530273438 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.4328]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(3.3508, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7555e3dd4a944998a95be0bbc31f932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.20519106090068817 NEG_MLL -537.832763671875 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.4251]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(3.4144, grad_fn=<SoftplusBackward0>) k Parameter containing:\n",
      "tensor(30., requires_grad=True)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING QR BATCH\n",
      "Running eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd31a7bbc58c469e8c75c36a3c882ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m     61\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# Number of runs\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m all_mean_rmse, all_mean_runtimes, all_std_rmse, all_std_runtimes \u001b[38;5;241m=\u001b[39m \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGP_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m plot_results(GP_classes, all_mean_rmse, all_mean_runtimes, all_std_rmse, all_std_runtimes, epochs)\n",
      "Cell \u001b[0;32mIn[87], line 30\u001b[0m, in \u001b[0;36mbenchmark\u001b[0;34m(GP_classes, train_dataset, test_dataset, epochs, seed, N)\u001b[0m\n\u001b[1;32m     27\u001b[0m all_runs_runtimes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[0;32m---> 30\u001b[0m     epoch_rmse, epoch_runtimes \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_gp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mGP_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43minducing_points\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     all_runs_rmse\u001b[38;5;241m.\u001b[39mappend(epoch_rmse)\n\u001b[1;32m     41\u001b[0m     all_runs_runtimes\u001b[38;5;241m.\u001b[39mappend(epoch_runtimes)\n",
      "Cell \u001b[0;32mIn[84], line 109\u001b[0m, in \u001b[0;36mtrain_gp\u001b[0;34m(GP_class, inducing_points, test_dataset, train_features, train_labels, epochs, device, dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m         epoch_rmse\u001b[38;5;241m.\u001b[39mappend(eval_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval finished\u001b[39m\u001b[38;5;124m\"\u001b[39m)    \n\u001b[0;32m--> 109\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epoch_rmse, epoch_runtimes\n",
      "Cell \u001b[0;32mIn[84], line 106\u001b[0m, in \u001b[0;36mtrain_gp.<locals>.train_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m#==================Evaluate============================\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning eval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m \u001b[43meval_gp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m epoch_rmse\u001b[38;5;241m.\u001b[39mappend(eval_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval finished\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m, in \u001b[0;36meval_gp\u001b[0;34m(model, test_dataset, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m neg_mlls \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/torch/utils/data/dataloader.py:440\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/torch/utils/data/dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1038\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1031\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1038\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/multiprocessing/context.py:289\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/softgp/lib/python3.12/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def benchmark(GP_classes, train_dataset, test_dataset, epochs=2, seed=42, N=3):\n",
    "    torch.manual_seed(6535)\n",
    "    np.random.seed(6535)\n",
    "    random.seed(6535)\n",
    "\n",
    "    num_inducing = 512\n",
    "    dtype = torch.float32\n",
    "    device = \"cpu\"\n",
    "    \n",
    "    all_mean_rmse = []\n",
    "    all_mean_runtimes = []\n",
    "    all_std_rmse = []\n",
    "    all_std_runtimes = []\n",
    "\n",
    "    #==================Inducing Points============================\n",
    "    train_features, train_labels = flatten_dataset(train_dataset)\n",
    "    kmeans = KMeans(n_clusters=num_inducing)\n",
    "    kmeans.fit(train_features)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    inducing_points = torch.tensor(centers).to(dtype=dtype, device=device)\n",
    "\n",
    "    for GP_class in GP_classes:\n",
    "        print(f\"Training {GP_class.__name__}...\")\n",
    "        \n",
    "        # Run the experiment N times and store results for each run\n",
    "        all_runs_rmse = []\n",
    "        all_runs_runtimes = []\n",
    "        \n",
    "        for run in range(N):\n",
    "            epoch_rmse, epoch_runtimes = train_gp(\n",
    "                GP_class,\n",
    "                inducing_points.clone(),\n",
    "                test_dataset,\n",
    "                train_features,\n",
    "                train_labels,\n",
    "                epochs,\n",
    "                device,\n",
    "                dtype\n",
    "            )\n",
    "            all_runs_rmse.append(epoch_rmse)\n",
    "            all_runs_runtimes.append(epoch_runtimes)\n",
    "\n",
    "        # Calculate mean and std deviation across the N runs\n",
    "        mean_rmse = np.mean(all_runs_rmse, axis=0)\n",
    "        std_rmse = np.std(all_runs_rmse, axis=0)\n",
    "        mean_runtimes = np.mean(all_runs_runtimes, axis=0)\n",
    "        std_runtimes = np.std(all_runs_runtimes, axis=0)\n",
    "\n",
    "        all_mean_rmse.append(mean_rmse)\n",
    "        all_mean_runtimes.append(mean_runtimes)\n",
    "        all_std_rmse.append(std_rmse)\n",
    "        all_std_runtimes.append(std_runtimes)\n",
    "\n",
    "    return all_mean_rmse, all_mean_runtimes, all_std_rmse, all_std_runtimes\n",
    "\n",
    "#==================Benchmark============================\n",
    "\n",
    "\n",
    "GP_classes = [SoftGP_test] \n",
    "epochs = 50\n",
    "N = 1 # Number of runs\n",
    "all_mean_rmse, all_mean_runtimes, all_std_rmse, all_std_runtimes = benchmark(GP_classes, train_dataset, test_dataset, epochs=epochs, seed=42, N=N)\n",
    "plot_results(GP_classes, all_mean_rmse, all_mean_runtimes, all_std_rmse, all_std_runtimes, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Softmax with temperature] All thresholds at 1e-3\n",
    "- Fixed T=1 (softmax) |   `RMSE : 0.18995238840579987`\n",
    "- Fixed T=.005        |   `RMSE : 0.15676772594451904`\n",
    "- Fixed T=1e-8        |   `RMSE : early blow up ~.9`\n",
    "- Learn T from 1 |`RMSE: 0.17583267390727997 NEG_MLL -95.2702407836914`\n",
    "- Learn T from 1e-4|`RMSE: 0.15030381083488464 NEG_MLL -177.95814514160156 `\n",
    "- Learn T from 1e-8|`RMSE: 0.16479668021202087 NEG_MLL -75.8147964477539`\n",
    "\n",
    "\n",
    "[new data]\n",
    "- Nearest neighbor trick k=1 T=1 |`RMSE:Early blow up`\n",
    "- Nearest neighbor trick k=5 T=1 |`RMSE: 0.14919526875019073`\n",
    "- Nearest neighbor trick k=10 T=1 |`RMSE: 0.1487170159816742`\n",
    "- Nearest neighbor trick k=26 T=1 |`RMSE: 0.14025409519672394`\n",
    "- Nearest neighbor trick k=30 T=1 |`RMSE: 0.14733223617076874 `\n",
    "- Nearest neighbor trick k=40 T=1 |`RMSE: 0.1309099793434143`\n",
    "- Nearest neighbor trick k=60 T=1 |`RMSE: 0.14369042217731476 `\n",
    "\n",
    "\n",
    "- Nearest neighbor trick k=40  T=.5 |`RMSE: 0.16032849252223969 `\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 0.1432650238275528 thresh 1e-7\n",
    "\n",
    "# RMSE: 0.14299191534519196 thresh 1e-3\n",
    "\n",
    "\n",
    "#RMSE: 0.16022315621376038 NEG_MLL -58.170013427734375 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.5337]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(2.8697, grad_fn=<SoftplusBackward0>) T=.5\n",
    "\n",
    "RMSE: 0.1340067833662033 NEG_MLL -81.39476013183594 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.3085]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(3.2416, grad_fn=<SoftplusBackward0>) neighbors =40\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477c3fe1f9d243aaa66facc5c986e125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:  50%|     | 1/2 [00:26<00:26, 26.02s/it, MLL=-5742.74853515625]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(369.2504, grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from gp.exact_gp.exact_gp import ExactGPModel,CGDMLL\n",
    "from gp.exact_gp.exact_gp import eval_gp as evgp\n",
    "from gpytorch.constraints import GreaterThan\n",
    "\n",
    "def train_exact(train_dataset, test_dataset,epochs):\n",
    "\n",
    "    dtype=torch.float32\n",
    "    device=\"cpu\"\n",
    "    lr=.01\n",
    "    learn_noise = False\n",
    "    torch.set_default_dtype(dtype)\n",
    "    torch.manual_seed(6535)\n",
    "    Kxxs = []\n",
    "    # Dataset preparation\n",
    "    train_x, train_y = flatten_dataset(train_dataset)\n",
    "    train_x = train_x.to(dtype=dtype, device=device)\n",
    "    train_y = train_y.to(dtype=dtype, device=device)\n",
    "\n",
    "    # Model\n",
    "    # inducing_points = train_x[:num_inducing, :].clone() # torch.rand(num_inducing, D).cuda()\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_constraint=GreaterThan(1e-1)).to(device=device)\n",
    "    likelihood.noise = torch.tensor([.5]).to(device=device)\n",
    "    model = ExactGPModel(train_x, train_y, likelihood, kernel=RBFKernel(), use_scale=True).to(device=device)\n",
    "    # mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    mll = CGDMLL(likelihood, model,max_cg_iters=50,cg_tolerance=1e-3)\n",
    "\n",
    "    # Training parameters\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # Set optimizer\n",
    "    if learn_noise:\n",
    "        params = model.parameters()\n",
    "        hypers = likelihood.parameters()\n",
    "    else:\n",
    "        params = model.parameters()\n",
    "        hypers = []\n",
    "        \n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': params},\n",
    "        {'params': hypers}\n",
    "    ], lr=lr)\n",
    "    lr_sched = lambda epoch: 1.0\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_sched)\n",
    "    \n",
    "    # Training loop\n",
    "    pbar = tqdm(range(epochs), desc=\"Optimizing MLL\")\n",
    "    for epoch in pbar:\n",
    "        t1 = time.perf_counter()\n",
    "\n",
    "        # Load batch\n",
    "        optimizer.zero_grad()\n",
    "        output = likelihood(model(train_x))\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "\n",
    "        # step optimizers and learning rate schedulers\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        t2 = time.perf_counter()\n",
    "\n",
    "        # Log\n",
    "        pbar.set_description(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        pbar.set_postfix(MLL=f\"{-loss.item()}\")\n",
    "\n",
    "        # Evaluate\n",
    "        #test_rmse, test_nll = evgp(model, likelihood, test_dataset, device=device)\n",
    "        #print(test_rmse)\n",
    "        k = model.covar_module(train_x)\n",
    "        print(torch.linalg.matrix_norm(k.to_dense(),ord='fro'))\n",
    "        Kxxs += k.to_dense()\n",
    "        model.train()\n",
    "        likelihood.train()\n",
    "\n",
    "    return model, likelihood,Kxxs\n",
    "\n",
    "model,_,Kxxs = train_exact(train_dataset,test_dataset,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4175f52de7b64f218422043706daee63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SoftGP_baseline...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00371abe18a14013a5c4d2ec4a36960d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING QR BATCH\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4d24dcc4e84fc2bff5f9e10e188588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.26991087198257446 NEG_MLL -1346.427001953125 NOISE 0.0010000001639127731 LENGTHSCALE tensor([[0.6336]], grad_fn=<SoftplusBackward0>) OUTPUTSCALE tensor(0.7653, grad_fn=<SoftplusBackward0>)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'kernels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[185], line 172\u001b[0m\n\u001b[1;32m    170\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;66;03m# Run for 150 epochs\u001b[39;00m\n\u001b[1;32m    171\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Number of runs\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m all_mean_rmse, all_mean_runtimes, all_mean_relative_errors, all_std_rmse, all_std_runtimes \u001b[38;5;241m=\u001b[39m \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGP_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m plot_results(GP_classes, all_mean_rmse, all_mean_runtimes, all_mean_relative_errors, all_std_rmse, all_std_runtimes, epochs)\n",
      "Cell \u001b[0;32mIn[185], line 140\u001b[0m, in \u001b[0;36mbenchmark\u001b[0;34m(GP_classes, train_dataset, test_dataset, epochs, seed, N)\u001b[0m\n\u001b[1;32m    137\u001b[0m all_runs_relative_errors \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# Store relative errors for each run\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[0;32m--> 140\u001b[0m     epoch_rmse, epoch_runtimes, relative_errors \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_gp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mGP_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43minducing_points\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     all_runs_rmse\u001b[38;5;241m.\u001b[39mappend(epoch_rmse)\n\u001b[1;32m    151\u001b[0m     all_runs_runtimes\u001b[38;5;241m.\u001b[39mappend(epoch_runtimes)\n",
      "Cell \u001b[0;32mIn[185], line 107\u001b[0m, in \u001b[0;36mtrain_gp\u001b[0;34m(GP_class, inducing_points, test_dataset, train_features, train_labels, epochs, device, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m             relative_error \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mmatrix_norm(K_xx \u001b[38;5;241m-\u001b[39m Q_xx, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfro\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mmatrix_norm(K_xx, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    105\u001b[0m             relative_errors\u001b[38;5;241m.\u001b[39mappend(relative_error\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m--> 107\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epoch_rmse, epoch_runtimes, relative_errors\n",
      "Cell \u001b[0;32mIn[185], line 99\u001b[0m, in \u001b[0;36mtrain_gp.<locals>.train_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m#==================Relative Error========================\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Compute the approximation and relative error with K_xx\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 99\u001b[0m     K_xx \u001b[38;5;241m=\u001b[39m \u001b[43mkernels\u001b[49m[epoch](train_features, train_features)\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m    100\u001b[0m     W_xz \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_interp(train_features)  \u001b[38;5;66;03m# Get interpolation weights\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     K_zz \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_mk_cov(model\u001b[38;5;241m.\u001b[39minducing_points)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kernels' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_results(GP_classes, all_mean_rmse, all_mean_runtimes, all_mean_relative_errors, all_std_rmse, all_std_runtimes, epochs):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))  # Add a third subplot for relative errors\n",
    "\n",
    "    for i, GP_class in enumerate(GP_classes):\n",
    "        epochs_range = range(1, epochs + 1)\n",
    "\n",
    "        # Plot RMSE\n",
    "        axes[0].plot(epochs_range, all_mean_rmse[i], label=f'{GP_class.__name__} RMSE')\n",
    "        axes[0].fill_between(epochs_range,\n",
    "                             [m - s for m, s in zip(all_mean_rmse[i], all_std_rmse[i])],\n",
    "                             [m + s for m, s in zip(all_mean_rmse[i], all_std_rmse[i])],\n",
    "                             alpha=0.3)\n",
    "        axes[0].set_title('RMSE per Epoch')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('RMSE')\n",
    "        axes[0].legend()\n",
    "\n",
    "        # Plot runtimes\n",
    "        axes[1].plot(epochs_range, all_mean_runtimes[i], label=f'{GP_class.__name__} Runtime')\n",
    "        axes[1].fill_between(epochs_range,\n",
    "                             [m - s for m, s in zip(all_mean_runtimes[i], all_std_runtimes[i])],\n",
    "                             [m + s for m, s in zip(all_mean_runtimes[i], all_std_runtimes[i])],\n",
    "                             alpha=0.3)\n",
    "        axes[1].set_title('Training Time per Epoch')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Time (s)')\n",
    "        axes[1].legend()\n",
    "\n",
    "        # Plot relative errors\n",
    "        axes[2].plot(epochs_range, all_mean_relative_errors[i], label=f'{GP_class.__name__} Relative Error')\n",
    "        axes[2].set_title('Relative Error per Epoch')\n",
    "        axes[2].set_xlabel('Epoch')\n",
    "        axes[2].set_ylabel('Relative Error')\n",
    "        axes[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def train_gp(GP_class, inducing_points, test_dataset, train_features, train_labels, epochs, device, dtype):\n",
    "    kernel = RBFKernel().to(device=device, dtype=dtype)\n",
    "    learn_noise = False\n",
    "    lr = .01\n",
    "    batch_size = 1024\n",
    "\n",
    "    model = GP_class(kernel,\n",
    "                     inducing_points,\n",
    "                     noise=1e-3,\n",
    "                     learn_noise=learn_noise,\n",
    "                     use_scale=True,\n",
    "                     dtype=dtype,\n",
    "                     solver=\"solve\",\n",
    "                     max_cg_iter=50,\n",
    "                     cg_tolerance=0.5,\n",
    "                     mll_approx=\"hutchinson\",\n",
    "                     fit_chunk_size=1024,\n",
    "                     use_qr=True)\n",
    "\n",
    "    epoch_runtimes = []\n",
    "    epoch_rmse = []\n",
    "    relative_errors = []  # Store relative errors per epoch\n",
    "\n",
    "    # Compute the exact K_xx kernel once at the start\n",
    "    # with torch.no_grad():\n",
    "    #     # sk = ScaleKernel(kernel).to(device)\n",
    "\n",
    "    if learn_noise:\n",
    "        params = model.parameters()\n",
    "    else:\n",
    "        params = filter_param(model.named_parameters(), \"likelihood.noise_covar.raw_noise\")\n",
    "    optimizer = torch.optim.Adam(params, lr=lr)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    def train_model():\n",
    "        #==================Train============================\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            epoch_start_time = time.time()\n",
    "\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch = x_batch.clone().detach().to(dtype=dtype, device=device)\n",
    "                y_batch = y_batch.clone().detach().to(dtype=dtype, device=device)\n",
    "                optimizer.zero_grad()\n",
    "                with gpytorch.settings.max_root_decomposition_size(100), max_cholesky_size(int(1.e7)):\n",
    "                    neg_mll = -model.mll(x_batch, y_batch)\n",
    "                neg_mll.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            model.fit(train_features, train_labels)\n",
    "            epoch_end_time = time.time()\n",
    "            epoch_runtimes.append(epoch_end_time - epoch_start_time)\n",
    "\n",
    "            #==================Evaluate============================\n",
    "            eval_results = eval_gp(model, test_dataset, device=device)\n",
    "            epoch_rmse.append(eval_results['rmse'])\n",
    "\n",
    "            #==================Relative Error========================\n",
    "            # Compute the approximation and relative error with K_xx\n",
    "            with torch.no_grad():\n",
    "                K_xx = kernels[epoch](train_features, train_features).evaluate()\n",
    "                W_xz = model._interp(train_features)  # Get interpolation weights\n",
    "                K_zz = model._mk_cov(model.inducing_points)\n",
    "                Q_xx = W_xz @ K_zz @ W_xz.T\n",
    "                print(torch.linalg.matrix_norm(K_xx - Q_xx, ord='fro') / torch.linalg.matrix_norm(K_xx, ord='fro'))\n",
    "                relative_error = torch.linalg.matrix_norm(K_xx - Q_xx, ord='fro') / torch.linalg.matrix_norm(K_xx, ord='fro')\n",
    "                relative_errors.append(relative_error.item())\n",
    "\n",
    "    train_model()\n",
    "    return epoch_rmse, epoch_runtimes, relative_errors  \n",
    "\n",
    "def benchmark(GP_classes, train_dataset, test_dataset, epochs=2, seed=42, N=3):\n",
    "    torch.manual_seed(6535)\n",
    "    np.random.seed(6535)\n",
    "    random.seed(6535)\n",
    "\n",
    "    num_inducing = 512\n",
    "    dtype = torch.float32\n",
    "    device = \"cpu\"\n",
    "    \n",
    "    all_mean_rmse = []\n",
    "    all_mean_runtimes = []\n",
    "    all_mean_relative_errors = []  # Store mean relative errors across runs\n",
    "    all_std_rmse = []\n",
    "    all_std_runtimes = []\n",
    "\n",
    "    #==================Inducing Points============================\n",
    "    train_features, train_labels = flatten_dataset(train_dataset)\n",
    "    kmeans = KMeans(n_clusters=num_inducing)\n",
    "    kmeans.fit(train_features)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    inducing_points = torch.tensor(centers).to(dtype=dtype, device=device)\n",
    "\n",
    "    for GP_class in GP_classes:\n",
    "        print(f\"Training {GP_class.__name__}...\")\n",
    "        \n",
    "        all_runs_rmse = []\n",
    "        all_runs_runtimes = []\n",
    "        all_runs_relative_errors = []  # Store relative errors for each run\n",
    "\n",
    "        for run in range(N):\n",
    "            epoch_rmse, epoch_runtimes, relative_errors = train_gp(\n",
    "                GP_class,\n",
    "                inducing_points.clone(),\n",
    "                test_dataset,\n",
    "                train_features,\n",
    "                train_labels,\n",
    "                epochs,\n",
    "                device,\n",
    "                dtype\n",
    "            )\n",
    "            all_runs_rmse.append(epoch_rmse)\n",
    "            all_runs_runtimes.append(epoch_runtimes)\n",
    "            all_runs_relative_errors.append(relative_errors)\n",
    "\n",
    "        # Calculate mean and std deviation across the N runs\n",
    "        mean_rmse = np.mean(all_runs_rmse, axis=0)\n",
    "        std_rmse = np.std(all_runs_rmse, axis=0)\n",
    "        mean_runtimes = np.mean(all_runs_runtimes, axis=0)\n",
    "        std_runtimes = np.std(all_runs_runtimes, axis=0)\n",
    "        mean_relative_errors = np.mean(all_runs_relative_errors, axis=0)\n",
    "\n",
    "        all_mean_rmse.append(mean_rmse)\n",
    "        all_mean_runtimes.append(mean_runtimes)\n",
    "        all_mean_relative_errors.append(mean_relative_errors)  # Store mean relative errors\n",
    "        all_std_rmse.append(std_rmse)\n",
    "        all_std_runtimes.append(std_runtimes)\n",
    "\n",
    "    return all_mean_rmse, all_mean_runtimes, all_mean_relative_errors, all_std_rmse, all_std_runtimes\n",
    "\n",
    "GP_classes = [SoftGP_baseline,SoftGP_test]\n",
    "epochs = 5 # Run for 150 epochs\n",
    "N = 1  # Number of runs\n",
    "all_mean_rmse, all_mean_runtimes, all_mean_relative_errors, all_std_rmse, all_std_runtimes = benchmark(GP_classes, train_dataset, test_dataset, epochs=epochs, seed=42, N=N)\n",
    "plot_results(GP_classes, all_mean_rmse, all_mean_runtimes, all_mean_relative_errors, all_std_rmse, all_std_runtimes, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "softgp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
