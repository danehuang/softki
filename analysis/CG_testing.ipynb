{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import random\n",
    "from os.path import exists\n",
    "from typing import *\n",
    "\n",
    "# Common data science imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from seaborn import heatmap\n",
    "from tqdm import tqdm, notebook as tqdm_notebook\n",
    "\n",
    "# GPyTorch and linear_operator imports\n",
    "import gpytorch\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel\n",
    "from gpytorch.constraints import *\n",
    "import linear_operator\n",
    "from linear_operator.settings import max_cholesky_size\n",
    "from linear_operator.operators.dense_linear_operator import DenseLinearOperator\n",
    "from linear_operator.utils.cholesky import psd_safe_cholesky\n",
    "\n",
    "# Custom soft GP and MLL imports\n",
    "from gp.soft_gp.soft_gp import SoftGP\n",
    "from gp.soft_gp.mll import HutchinsonPseudoLoss\n",
    "from linear_solver.cg import linear_cg\n",
    "\n",
    "# Data analysis and UCI dataset\n",
    "\n",
    "# Utility functions for dataset handling\n",
    "from gp.util import flatten_dataset, split_dataset, filter_param\n",
    "\n",
    "# Experiment tracking\n",
    "import wandb\n",
    "\n",
    "# System path adjustments\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_gp(model, test_dataset: Dataset, device=\"cuda:0\") -> float:\n",
    "    preds = []\n",
    "    neg_mlls = []\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,num_workers=1)\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        preds += [(model.pred(x_batch) - y_batch).detach().cpu()**2]\n",
    "        neg_mlls += [-model.mll(x_batch, y_batch).detach().cpu()]\n",
    "    rmse = torch.sqrt(torch.sum(torch.cat(preds)) / len(test_dataset)).item()\n",
    "    neg_mll = torch.sum(torch.tensor(neg_mlls))\n",
    "            \n",
    "    print(\"RMSE:\", rmse, \"NEG_MLL\", neg_mll.item(), \"NOISE\", model.noise.cpu().item(), \"LENGTHSCALE\", model.get_lengthscale(), \"OUTPUTSCALE\", model.get_outputscale())# \"T\",model.T)\n",
    "    \n",
    "    return {\n",
    "        \"rmse\": rmse,\n",
    "        \"nll\": neg_mll,\n",
    "    }   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE (45730, 10)\n"
     ]
    }
   ],
   "source": [
    "#==================Dataset============================\n",
    "from data.get_uci import ElevatorsDataset,PoleteleDataset,ProteinDataset\n",
    "# # dataset = ElevatorsDataset(\"../data/uci_datasets/uci_datasets/elevators/data.csv\")\n",
    "# dataset = PoleteleDataset(\"../data/uci_datasets/uci_datasets/pol/data.csv\")\n",
    "dataset = ProteinDataset(\"../data/uci_datasets/uci_datasets/protein/data.csv\")\n",
    "# dataset = CTSlicesDataset(\"../data/uci_datasets/uci_datasets/slice/data.csv\")\n",
    "train_dataset, val_dataset, test_dataset = split_dataset(\n",
    "    dataset,\n",
    "    train_frac=9/10, #TODO change to real vals \n",
    "    val_frac=0/10\n",
    ")\n",
    "\n",
    "def plot_results(all_mean_rmse, all_mean_runtimes, all_std_rmse, all_std_runtimes, epochs,  legend_names):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    epochs_range = range(1, epochs + 1)\n",
    "\n",
    "    # Plot RMSE per Epoch for each model (baseline + CG tolerances)\n",
    "    for i in range(len(legend_names)):\n",
    "        label = legend_names[i]  # Use the provided names from legend_names list\n",
    "        axes[0].plot(epochs_range, all_mean_rmse[i], label=label)\n",
    "        \n",
    "        # Fill between the RMSE values for standard deviation\n",
    "        axes[0].fill_between(epochs_range,\n",
    "                             [m - s for m, s in zip(all_mean_rmse[i], all_std_rmse[i])],\n",
    "                             [m + s for m, s in zip(all_mean_rmse[i], all_std_rmse[i])],\n",
    "                             alpha=0.3)\n",
    "\n",
    "    axes[0].set_title('RMSE per Epoch')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('RMSE')\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Plot Training Time per Epoch for each model (baseline + CG tolerances)\n",
    "    for i in range(len(legend_names)):\n",
    "        label = legend_names[i]  # Use the provided names from legend_names list\n",
    "        axes[1].plot(epochs_range, all_mean_runtimes[i], label=label)\n",
    "        \n",
    "        # Fill between the runtime values for standard deviation\n",
    "        axes[1].fill_between(epochs_range,\n",
    "                             [m - s for m, s in zip(all_mean_runtimes[i], all_std_runtimes[i])],\n",
    "                             [m + s for m, s in zip(all_mean_runtimes[i], all_std_runtimes[i])],\n",
    "                             alpha=0.3)\n",
    "\n",
    "    axes[1].set_title('Training Time per Epoch')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Time (s)')\n",
    "    # axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('protein_solvers.png')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def train_gp(GP_class, inducing_points, test_dataset, train_features, train_labels, epochs, device, dtype, model_config=None):\n",
    "    print(device)\n",
    "    print(inducing_points.device)\n",
    "    model_config = model_config or {}\n",
    "    kernel = RBFKernel().to(device=device, dtype=dtype)\n",
    "    # kernel = RBFKernel()\n",
    "    learn_noise = model_config.get(\"learn_noise\", False)\n",
    "    lr = model_config.get(\"learning_rate\", 0.01)\n",
    "    batch_size = model_config.get(\"batch_size\", 1024)\n",
    "\n",
    "    model = GP_class(\n",
    "        kernel,\n",
    "        inducing_points,\n",
    "        noise=model_config.get(\"noise\", 1e-3),\n",
    "        learn_noise=learn_noise,\n",
    "        use_scale=model_config.get(\"use_scale\", True),\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "        max_cg_iter=1000,\n",
    "        solver=model_config.get(\"solver\", \"solve\"),\n",
    "        mll_approx=model_config.get(\"mll_approx\", \"hutchinson\"),\n",
    "        fit_chunk_size=model_config.get(\"fit_chunk_size\", 1024),\n",
    "        use_qr=model_config.get(\"use_qr\", True),\n",
    "        hutch_solver = model_config.get(\"hutch_solver\", \"solve\"),\n",
    "    )\n",
    "\n",
    "\n",
    "    epoch_runtimes = []\n",
    "    epoch_rmse = []\n",
    "\n",
    "    # pbar = tqdm(range(epochs), desc=\"Optimizing MLL\")\n",
    "    if learn_noise:\n",
    "        params = model.parameters()\n",
    "    else:\n",
    "        params = filter_param(model.named_parameters(), \"likelihood.noise_covar.raw_noise\")\n",
    "    optimizer = torch.optim.Adam(params, lr=lr)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    def train_model():\n",
    "        #==================Train============================\n",
    "        for _ in tqdm(range(epochs)):\n",
    "            print(\"training current epoch\")\n",
    "            epoch_start_time = time.time()\n",
    "\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch = x_batch.clone().detach().to(dtype=dtype, device=device)\n",
    "                y_batch = y_batch.clone().detach().to(dtype=dtype, device=device)\n",
    "                optimizer.zero_grad()\n",
    "                with gpytorch.settings.max_root_decomposition_size(100), max_cholesky_size(int(1.e7)), gpytorch.settings.max_preconditioner_size(15):\n",
    "                    neg_mll = -model.mll(x_batch, y_batch)\n",
    "                neg_mll.backward()\n",
    "                optimizer.step()\n",
    "            model.fit(train_features, train_labels)\n",
    "            epoch_end_time = time.time()\n",
    "            epoch_runtimes.append(epoch_end_time - epoch_start_time)\n",
    "\n",
    "            #==================Evaluate============================\n",
    "            print(\"Running eval\")\n",
    "            eval_results = eval_gp(model, test_dataset, device=device)\n",
    "            epoch_rmse.append(eval_results['rmse'])\n",
    "            print(\"eval finished\")    \n",
    "    train_model()\n",
    "    return epoch_rmse, epoch_runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(train_dataset, test_dataset, epochs=2, seed=42, N=3, configs=None):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    num_inducing = 512\n",
    "    dtype = torch.float32\n",
    "    device = \"cuda:1\"\n",
    "    \n",
    "    all_mean_rmse = []\n",
    "    all_mean_runtimes = []\n",
    "    all_std_rmse = []\n",
    "    all_std_runtimes = []\n",
    "\n",
    "    #==================Inducing Points============================\n",
    "    train_features, train_labels = flatten_dataset(train_dataset)\n",
    "    kmeans = KMeans(n_clusters=num_inducing)\n",
    "    kmeans.fit(train_features)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    inducing_points = torch.tensor(centers).to(dtype=dtype, device=device)\n",
    "\n",
    "    if configs is None:\n",
    "        raise ValueError(\"You must provide a list of configurations in 'configs'\")\n",
    "\n",
    "    for config in configs:\n",
    "        all_runs_rmse = []\n",
    "        all_runs_runtimes = []\n",
    "\n",
    "        solver_name = config.get(\"solver\", \"Unknown Solver\")\n",
    "        print(f\"Running model with solver '{solver_name}'\")\n",
    "\n",
    "        for run in range(N):\n",
    "            epoch_rmse, epoch_runtimes = train_gp(\n",
    "                SoftGP,\n",
    "                inducing_points,\n",
    "                test_dataset,\n",
    "                train_features,\n",
    "                train_labels,\n",
    "                epochs,\n",
    "                device,\n",
    "                dtype,\n",
    "                model_config=config  # Pass current config\n",
    "            )\n",
    "            all_runs_rmse.append(epoch_rmse)\n",
    "            all_runs_runtimes.append(epoch_runtimes)\n",
    "\n",
    "        # Calculate mean and std deviation across the N runs for the current configuration\n",
    "        mean_rmse = np.mean(all_runs_rmse, axis=0)\n",
    "        std_rmse = np.std(all_runs_rmse, axis=0)\n",
    "        mean_runtimes = np.mean(all_runs_runtimes, axis=0)\n",
    "        std_runtimes = np.std(all_runs_runtimes, axis=0)\n",
    "\n",
    "        all_mean_rmse.append(mean_rmse)\n",
    "        all_mean_runtimes.append(mean_runtimes)\n",
    "        all_std_rmse.append(std_rmse)\n",
    "        all_std_runtimes.append(std_runtimes)\n",
    "\n",
    "    return all_mean_rmse, all_mean_runtimes, all_std_rmse, all_std_runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CG Fit Testing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692d6b70e78d46dd8b5c027ee6ef58c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model with solver 'cg'\n",
      "cuda:1\n",
      "cuda:1\n",
      "Using softmax_interp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training current epoch\n",
      "USING PRECONDITIONER\n",
      "Running eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:04<04:04,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7888864278793335 NEG_MLL -23808.74609375 NOISE 0.0010000000474974513 LENGTHSCALE tensor([[0.5775]], grad_fn=<ToCopyBackward0>) OUTPUTSCALE tensor(0.9086, grad_fn=<ToCopyBackward0>)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING PRECONDITIONER\n",
      "Running eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:09<03:41,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.777450680732727 NEG_MLL -21494.501953125 NOISE 0.0010000000474974513 LENGTHSCALE tensor([[0.6220]], grad_fn=<ToCopyBackward0>) OUTPUTSCALE tensor(1.1509, grad_fn=<ToCopyBackward0>)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING PRECONDITIONER\n",
      "Running eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:13<03:22,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7741975784301758 NEG_MLL -19945.498046875 NOISE 0.0010000000474974513 LENGTHSCALE tensor([[0.6307]], grad_fn=<ToCopyBackward0>) OUTPUTSCALE tensor(1.4051, grad_fn=<ToCopyBackward0>)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING PRECONDITIONER\n",
      "Running eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:17<03:12,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7806186079978943 NEG_MLL -18787.7578125 NOISE 0.0010000000474974513 LENGTHSCALE tensor([[0.6237]], grad_fn=<ToCopyBackward0>) OUTPUTSCALE tensor(1.6664, grad_fn=<ToCopyBackward0>)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING PRECONDITIONER\n",
      "Running eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:21<03:05,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7725435495376587 NEG_MLL -17924.861328125 NOISE 0.0010000000474974513 LENGTHSCALE tensor([[0.6077]], grad_fn=<ToCopyBackward0>) OUTPUTSCALE tensor(1.9269, grad_fn=<ToCopyBackward0>)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING PRECONDITIONER\n",
      "Running eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:25<03:00,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7834170460700989 NEG_MLL -17095.306640625 NOISE 0.0010000000474974513 LENGTHSCALE tensor([[0.6014]], grad_fn=<ToCopyBackward0>) OUTPUTSCALE tensor(2.1895, grad_fn=<ToCopyBackward0>)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING PRECONDITIONER\n",
      "Running eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:32<03:33,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.771926999092102 NEG_MLL -16516.91796875 NOISE 0.0010000000474974513 LENGTHSCALE tensor([[0.5778]], grad_fn=<ToCopyBackward0>) OUTPUTSCALE tensor(2.4506, grad_fn=<ToCopyBackward0>)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING PRECONDITIONER\n",
      "Running eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:37<03:40,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7870786786079407 NEG_MLL -15981.48046875 NOISE 0.0010000000474974513 LENGTHSCALE tensor([[0.5661]], grad_fn=<ToCopyBackward0>) OUTPUTSCALE tensor(2.7107, grad_fn=<ToCopyBackward0>)\n",
      "eval finished\n",
      "training current epoch\n",
      "USING PRECONDITIONER\n",
      "Running eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:41<03:17,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7860366106033325 NEG_MLL -15365.314453125 NOISE 0.0010000000474974513 LENGTHSCALE tensor([[0.5604]], grad_fn=<ToCopyBackward0>) OUTPUTSCALE tensor(2.9656, grad_fn=<ToCopyBackward0>)\n",
      "eval finished\n",
      "training current epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:43<03:20,  4.88s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m     13\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# Number of runs\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m all_mean_rmse, all_mean_runtimes, all_std_rmse, all_std_runtimes \u001b[38;5;241m=\u001b[39m \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6535\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfigs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 33\u001b[0m, in \u001b[0;36mbenchmark\u001b[0;34m(train_dataset, test_dataset, epochs, seed, N, configs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning model with solver \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msolver_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[0;32m---> 33\u001b[0m     epoch_rmse, epoch_runtimes \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_gp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mSoftGP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43minducing_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass current config\u001b[39;49;00m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     all_runs_rmse\u001b[38;5;241m.\u001b[39mappend(epoch_rmse)\n\u001b[1;32m     45\u001b[0m     all_runs_runtimes\u001b[38;5;241m.\u001b[39mappend(epoch_runtimes)\n",
      "Cell \u001b[0;32mIn[3], line 115\u001b[0m, in \u001b[0;36mtrain_gp\u001b[0;34m(GP_class, inducing_points, test_dataset, train_features, train_labels, epochs, device, dtype, model_config)\u001b[0m\n\u001b[1;32m    113\u001b[0m         epoch_rmse\u001b[38;5;241m.\u001b[39mappend(eval_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval finished\u001b[39m\u001b[38;5;124m\"\u001b[39m)    \n\u001b[0;32m--> 115\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epoch_rmse, epoch_runtimes\n",
      "Cell \u001b[0;32mIn[3], line 98\u001b[0m, in \u001b[0;36mtrain_gp.<locals>.train_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining current epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 98\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/softgp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/softgp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/softgp/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/softgp/lib/python3.11/site-packages/torch/utils/data/dataset.py:419\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/softgp/lib/python3.11/site-packages/torch/utils/data/dataset.py:419\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/soft-gp/data/get_uci.py:86\u001b[0m, in \u001b[0;36mUCIDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     83\u001b[0m     idx \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     85\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     89\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(features)\n",
      "File \u001b[0;32m~/anaconda3/envs/softgp/lib/python3.11/site-packages/pandas/core/indexing.py:1183\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/softgp/lib/python3.11/site-packages/pandas/core/frame.py:4211\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4192\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4193\u001b[0m \u001b[38;5;124;03mQuickly retrieve single value at passed column and index.\u001b[39;00m\n\u001b[1;32m   4194\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4208\u001b[0m \u001b[38;5;124;03m`self.columns._index_as_unique`; Caller is responsible for checking.\u001b[39;00m\n\u001b[1;32m   4209\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m takeable:\n\u001b[0;32m-> 4211\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[index]\n\u001b[1;32m   4214\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_item_cache(col)\n",
      "File \u001b[0;32m~/anaconda3/envs/softgp/lib/python3.11/site-packages/pandas/core/frame.py:4010\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   4006\u001b[0m \u001b[38;5;66;03m# icol\u001b[39;00m\n\u001b[1;32m   4007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4008\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[i]\n\u001b[0;32m-> 4010\u001b[0m     col_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4011\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_box_col_values(col_mgr, i)\n\u001b[1;32m   4013\u001b[0m     \u001b[38;5;66;03m# this is a cached value, mark it so\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/softgp/lib/python3.11/site-packages/pandas/core/internals/managers.py:1021\u001b[0m, in \u001b[0;36mBlockManager.iget\u001b[0;34m(self, i, track_ref)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;66;03m# shortcut for select a single-dim from a 2-dim BM\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(values)))\n\u001b[0;32m-> 1021\u001b[0m nb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrack_ref\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1023\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SingleBlockManager(nb, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "configs = [\n",
    "    {\"solver\": \"cg\", \"hutch_solver\": \"solve\",\"cg_tolerance\": 1e-4,\"use_qr\": False},\n",
    "    {\"solver\": \"cg\", \"hutch_solver\": \"solve\",\"cg_tolerance\": 1e-3,\"use_qr\": False},\n",
    "    {\"solver\": \"cg\", \"hutch_solver\": \"solve\",\"cg_tolerance\": 1e-2,\"use_qr\": False},\n",
    "    {\"solver\": \"cg\", \"hutch_solver\": \"solve\",\"cg_tolerance\": 1e-1,\"use_qr\": False},\n",
    "    {\"solver\": \"solve\", \"hutch_solver\": \"solve\",\"cg_tolerance\": 1e-4,\"use_qr\": True},\n",
    "    {\"solver\": \"cholesky\", \"hutch_solver\": \"solve\",\"use_qr\": False},\n",
    "    {\"solver\": \"solve\", \"hutch_solver\": \"solve\",\"use_qr\": False},\n",
    "]\n",
    "legend_names = ['QR Solve', 'CG Solver 1e-4','CG Solver 1e-3','CG Solver 1e-2','CG Solver 1e-1','Cholesky Solver',\"Direct Solver\"]\n",
    "\n",
    "epochs = 50\n",
    "N = 1 # Number of runs\n",
    "all_mean_rmse, all_mean_runtimes, all_std_rmse, all_std_runtimes = benchmark(train_dataset, test_dataset, epochs=epochs, seed=6535, N=N, configs=configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results2(all_mean_rmse, all_mean_runtimes, all_std_rmse, all_std_runtimes, epochs,  legend_names):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "    epochs_range = range(1, epochs + 1)\n",
    "\n",
    "    # Plot RMSE per Epoch for each model (baseline + CG tolerances)\n",
    "    for i in range(len(legend_names)):\n",
    "        label = legend_names[i]  # Use the provided names from legend_names list\n",
    "        if \"CG\" in label:\n",
    "            style = \"-\"\n",
    "        elif \"Cholesky\" in label:\n",
    "            style = \"--\"\n",
    "        else:\n",
    "            style = \":\"\n",
    "        if \"QR\" in label:\n",
    "            width = 3\n",
    "        elif \"CG\" in label:\n",
    "            width = 1\n",
    "        else:\n",
    "            width = 1\n",
    "        axes.plot(epochs_range, all_mean_rmse[i], label=label, linestyle=style, linewidth=width)\n",
    "        \n",
    "        # Fill between the RMSE values for standard deviation\n",
    "        axes.fill_between(epochs_range,\n",
    "                             [m - s for m, s in zip(all_mean_rmse[i], all_std_rmse[i])],\n",
    "                             [m + s for m, s in zip(all_mean_rmse[i], all_std_rmse[i])],\n",
    "                             alpha=0.3)\n",
    "\n",
    "    axes.set_title('RMSE per Epoch')\n",
    "    axes.set_xlabel('Epoch', fontsize=12)\n",
    "    axes.set_ylabel('Test RMSE', fontsize=12)\n",
    "    axes.tick_params(axis='both', which='major', labelsize=12)\n",
    "    axes.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('protein_solvers.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_names = ['CG Solver 1e-4','CG Solver 1e-3','CG Solver 1e-2','CG Solver 1e-1', 'QR Solve', 'Cholesky Solver',\"Direct Solver\"]\n",
    "# tolerance_values = [None,1e-4, 1e-3, 1e-2, 1e-1]\n",
    "plot_results2(all_mean_rmse, all_mean_runtimes, all_std_rmse, all_std_runtimes, epochs, legend_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "softgp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
